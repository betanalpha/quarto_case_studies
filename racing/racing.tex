% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Stan

Program}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Randomized Time Trial},
  pdfauthor={Michael Betancourt},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Randomized Time Trial}
\author{Michael Betancourt}
\date{August 2024}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
Modeling the outcome of competitions, for example games between
competing sports teams or tests between students and a standardized set
of questions, is a common statistics application. Different types of
competitions, however, are more or less compelling to certain audiences.
In this case study I consider a Bayesian analysis of a somewhat niche
competition that also happens to be particular compelling to the author
-- racing to see who can finish a modified version of a thirty year old
video game as quickly as possible.

\section{Super Metroid Map Randomizer
Races}\label{super-metroid-map-randomizer-races}

In the era of the Super Nintendo Entertainment System® the assets
comprising each video game -- such as code, visuals, and music -- were
stored in the read-only memory, or \textbf{ROM}, of physical cartridges.
\textbf{ROM hacks} rearrange the assets of a particular game, and in
some cases include assets from other games or even entirely new assets,
to create novel gaming experiences. Many popular ROM hacks, for example,
add quality of life features to make older games less frustrating to
play. Others focus on drastically increasing the difficulty of existing
games while still others offer the ability to randomize locations,
items, and more so that each new playthrough is unique.

Super Metroid® was first released for the Super Nintendo Entertainment
System® in 1994. The game's well-designed core mechanics interact
surprisingly well with unintended bugs, resulting in fast-paced and
highly-technical game play that has long been a favorite target of the
ROM hacking community.

One prominent example is the \href{https://maprando.com}{Super Metroid
Map Randomizer} ({``Super Metroid Map Rando,''} n.d.), or
\emph{MapRando} for short. The Super Metroid Map Randomizer is an
\href{https://github.com/blkerby/MapRandomizer}{open source project}
started in 2021 that randomizes individual rooms, items, objectives, and
more while also avoiding any inconsistencies that would prevent players
from completing the game. Randomization options are extensive and can be
configured to control everything from the topology of the room placement
to the difficulty of the techniques needed for completion. Each realized
map is referred to as a \emph{seed} for the seed that initializes the
behavior of the underlying pseudo-random number generator.

By 2024 the project had stimulated a passionate user community that not
only played the games individually but also started to race against each
other to see who could finish a particular seed the fastest. Because
some seeds end up being easier to finish than others the races tend to
be a bit chaotic and consistently entertaining.

Community races are even organized and recorded on the non-commercial
speed running website \href{https://racetime.gg/smr}{racetime.gg}
({``Super Metroid Randomizer \textbar{} Racetime.gg,''} n.d.).
Conveniently this organization makes data on previous races, including
individual entrants and their race outcomes, readily accessible. The
availability of this data in turn puts us in a position to infer and
compare the skill of those entrants and predict the outcome of future
races.

\section{Environment Setup}\label{environment-setup}

Before exploring that data we'll need to set up our local \texttt{R}
environment.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{family=}\StringTok{"serif"}\NormalTok{, }\AttributeTok{las=}\DecValTok{1}\NormalTok{, }\AttributeTok{bty=}\StringTok{"l"}\NormalTok{,}
    \AttributeTok{cex.axis=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.lab=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.main=}\DecValTok{1}\NormalTok{,}
    \AttributeTok{xaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{yaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{library}\NormalTok{(rstan)}
\FunctionTok{rstan\_options}\NormalTok{(}\AttributeTok{auto\_write =} \ConstantTok{TRUE}\NormalTok{)            }\CommentTok{\# Cache compiled Stan programs}
\FunctionTok{options}\NormalTok{(}\AttributeTok{mc.cores =}\NormalTok{ parallel}\SpecialCharTok{::}\FunctionTok{detectCores}\NormalTok{()) }\CommentTok{\# Parallelize chains}
\NormalTok{parallel}\SpecialCharTok{:::}\FunctionTok{setDefaultClusterOptions}\NormalTok{(}\AttributeTok{setup\_strategy =} \StringTok{"sequential"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To facilitate the implementation of Bayesian inference we'll also need
my recommended
\href{https://github.com/betanalpha/mcmc_diagnostics}{diagnostics} and
\href{https://github.com/betanalpha/mcmc_visualization_tools}{visualization}
tools.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util }\OtherTok{\textless{}{-}} \FunctionTok{new.env}\NormalTok{()}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mcmc\_analysis\_tools\_rstan.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}mcmc\_visualization\_tools.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}
\end{Highlighting}
\end{Shaded}

\section{Data Exploration}\label{sec:data-exploration}

To assemble the full data set I programmatically scraped
\texttt{https://racetime.gg/smr} for all races with the title
\texttt{Map\ Rando} that also include a link to the MapRando
configuration in their description. This then allowed me to collect
additional information on the MapRando version while also restricting
consideration to only those seeds with a \texttt{Hard} skill assumption
and \texttt{Tricky} item progression setting.

For each valid race I then scraped information on the individual
participants, in particular whether they finished the race or forfeited
and, if they finished, what their finish time was in seconds. Forfeits
are also referred to as ``did not finish'' or ``DNF''. Although forfeit
times are available on \texttt{https://racetime.gg/smr} interactively
they are difficult to extract programmatically and I consequently did
not include them.

Following the \texttt{racetime.gg} terminology I will refer to
individual participants in a race as \textbf{entrants} and their
participation into a particular race as an \textbf{entrance}. For
programming convenience I encoded the individual entrant usernames into
sequential numerical labels that can also be used for indexing.

Each race consists of a variable number of entrances, with each entrance
resulting in either a finish time or a forfeit. To accommodate this
ragged structure I organized the finish entrances and forfeit entrances
for all races into single arrays that are complemented with indexing
arrays for straightforward retrieval of individual race information.

The data collection scripts, translation between entrant indices and
usernames, and final data are all accessible in the
\href{https://github.com/betanalpha/quarto_chapters/tree/main/case_studies/racing/data}{GitHub
repository} for this chapter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/entrant\_level\_defs.csv"}\NormalTok{)}

\NormalTok{race\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_info.csv"}\NormalTok{)}
\NormalTok{race\_entrant\_f\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_entrant\_f\_info.csv"}\NormalTok{)}
\NormalTok{race\_entrant\_dnf\_info }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/race\_entrant\_dnf\_info.csv"}\NormalTok{)}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"N\_races"} \OtherTok{=} \FunctionTok{nrow}\NormalTok{(race\_info),}
             \StringTok{"N\_entrants"} \OtherTok{=} \FunctionTok{nrow}\NormalTok{(entrant\_info),}
             \StringTok{"race\_N\_entrants\_f"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f,}
             \StringTok{"race\_N\_entrants\_dnf"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
             \StringTok{"race\_f\_start\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs,}
             \StringTok{"race\_f\_end\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs,}
             \StringTok{"race\_dnf\_start\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs,}
             \StringTok{"race\_dnf\_end\_idxs"} \OtherTok{=}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs,}
             \StringTok{"race\_entrant\_f\_idxs"} \OtherTok{=}\NormalTok{ race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs,}
             \StringTok{"race\_entrant\_f\_times"} \OtherTok{=}\NormalTok{  race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
             \StringTok{"N\_entrances\_fs"} \OtherTok{=} \FunctionTok{length}\NormalTok{(race\_entrant\_f\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs),}
             \StringTok{"race\_entrant\_dnf\_idxs"} \OtherTok{=}\NormalTok{ race\_entrant\_dnf\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs,}
             \StringTok{"N\_entrances\_dnfs"} \OtherTok{=} \FunctionTok{length}\NormalTok{(race\_entrant\_dnf\_info}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs))}
\end{Highlighting}
\end{Shaded}

Altogether the data spans 192 races across the first eight months of
2024.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}\%i total races\textquotesingle{}}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_races))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
192 total races
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}First Race: \%s\textquotesingle{}}\NormalTok{, race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
First Race: 2024-01-09T21:39:16.610866+00:00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}Last Race: \%s\textquotesingle{}}\NormalTok{,}
\NormalTok{            race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes[}\FunctionTok{length}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{race\_datetimes)]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Last Race: 2024-07-27T23:28:49.606056+00:00
\end{verbatim}

Those races included 107 distinct entrants.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}\%i total entrants\textquotesingle{}}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_entrants))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
107 total entrants
\end{verbatim}

While the majority of races include at least five entrants some include
over thirty.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                    \DecValTok{0}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{3}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Total Entrants Per Race"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-6-1.pdf}

Similarly most races see most entrants finishing but some races,
presumable using more difficult seeds, can see over half of the entrants
forfeit.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf }\SpecialCharTok{/}
\NormalTok{                    (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf),}
                    \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.02}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Proportion of Forfeits Per Race"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-7-1.pdf}

The finish times across races vary substantially, peaking near an hour
but stretching from half an hour all the way to multiple hours. This
suggests that player skill, seed difficulty, or some combination of the
two, is highly variable from race to race.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{500}\NormalTok{, }\DecValTok{10}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Finish Time (minutes)"}\NormalTok{, }\AttributeTok{main=}\StringTok{"All Races"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-8-1.pdf}

If we isolate the finish times for a few entrants near the top of the
\texttt{https://racetime.gg/smr} leader boards then we see much less
variability, especially in the upper tail.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{91}\NormalTok{)) \{}
\NormalTok{  times }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)]}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{220}\NormalTok{, }\DecValTok{10}\NormalTok{,}
                      \AttributeTok{xlab=}\StringTok{"Finish Time (minutes)"}\NormalTok{,}
                      \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-9-1.pdf}

Overall participation and proportion of forfeits exhibits its own
heterogeneity across the individual entrants.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{entrant\_f\_idxs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
  \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{\}}

\NormalTok{entrant\_dnf\_idxs }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
  \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{\}}

\NormalTok{N\_entrant\_f\_races }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                            \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{length}\NormalTok{(}\FunctionTok{entrant\_f\_idxs}\NormalTok{(e)))}
\NormalTok{N\_entrant\_dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                              \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{length}\NormalTok{(}\FunctionTok{entrant\_dnf\_idxs}\NormalTok{(e)))}

\FunctionTok{barplot}\NormalTok{(N\_entrant\_f\_races,}
        \AttributeTok{space=}\DecValTok{0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark\_teal, }\AttributeTok{border=}\StringTok{"white"}\NormalTok{,}
        \AttributeTok{xlab=}\StringTok{"Entrant Index"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Total Races Finished"}\NormalTok{)}

\FunctionTok{barplot}\NormalTok{(N\_entrant\_dnf\_races,}
        \AttributeTok{space=}\DecValTok{0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark\_teal, }\AttributeTok{border=}\StringTok{"white"}\NormalTok{,}
        \AttributeTok{xlab=}\StringTok{"Entrant Index"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Total Races Forfeited"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-10-1.pdf}

There are many more ways that we could dive further into the data here,
but without domain expertise to guide us it's easy to get lost. Instead
let's leverage what understanding we've developed into an initial model.

\section{Model Development}\label{model-development}

To make the modeling process as manageable as possible we will start
simple and then add features iteratively.

\subsection{Model 1}\label{model-1}

To begin let's ignore forfeits altogether and instead focus on modeling
the finish times of the entrants who do not forfeit in each race.

\subsubsection{Observational Model}\label{observational-model}

One of the challenging aspects of modeling races in general is that
individual entrant behavior can depend on their position at any given
time. For example an entrant in first place might slow their pace to
stay just ahead of the entrant in second place, while racers in lower
places might play more aggressively in an attempt to catch up. While
some MapRando race entrants live-stream their play publicly the
community largely follows the rules of \texttt{https://racetime.gg/smr}
which disallow entrants from following the progress of any other
entrants.

Consequently entrants are mostly ignorant of their position during
races, at least until the first entrants finish and post their finish
times on the active \texttt{https://racetime.gg/smr} race page. This
suggest that modeling the finish time of each entrant independently of
the other entrants, without having to worry about interactions within
each race, is a reasonable approximation to the true race dynamics.

Now a particularly crude model of independent finish times might assume
that the finish times across all races concentrate around some common
baseline value, \[
\mu = t_{\mathrm{baseline}} = \exp(\eta) \cdot 1 \text{ second}.
\] Not all races, however, are the same.

For example some race seeds result in map layouts that require traveling
longer distances than others and some require executing difficult
techniques that usually take longer to complete than others. We could
account for this heterogeneity with a separate baseline finish time for
each seed, but we could also account for it by proportionally modifying
the common baseline, \begin{align*}
\mu_{r}
&=
t_{\mathrm{baseline}} \cdot \delta_{\mathrm{difficulty}, r}
\\
&=
\exp(\eta) \cdot \exp( \lambda_{\mathrm{difficulty}, r} )
\cdot 1 \text{ second}
\\
&=
\exp(\eta + \lambda_{\mathrm{difficulty}, r}) \cdot 1 \text{ second}.
\end{align*}

Similarly not all entrants are the same. The entrants who are more
experienced with Super Metroid® game play in general, and MapRando game
play in particular, should be able to finish a random seed faster than
those who are less experienced. Again we can model this with a
proportional modification to the common baseline, \begin{align*}
\mu_{re}
&=
t_{\mathrm{baseline}}
\cdot \delta_{\mathrm{difficulty}, r}
\cdot \frac{1}{\delta_{\mathrm{skill}, e}}
\\
&=
\exp(\eta)
\cdot \exp( \lambda_{\mathrm{difficulty}, r} )
\cdot \frac{1}{\exp( \lambda_{\mathrm{skill}, e} ) }
\cdot 1 \text{ second}
\\
&=
\exp(\eta + \lambda_{\mathrm{difficulty}, r} - \lambda_{\mathrm{skill}, e})
\cdot 1 \text{ second}.
\end{align*}

To complete our observational model we need to model the variation of
finish times around these baselines. One immediate possibility is the
gamma family of probability density functions, not in its conventional
parameterization but rather in its mean-dispersion parameterization. For
example the gamma family of probability density functions is typically
parameterized in terms of a shape parameter \(\alpha\) and a scale
parameter \(\beta\). We can also parameterize this same family, however,
in terms of a location parameter \[
\mu = \text{mean}(\alpha, \beta) = \frac{\alpha}{\beta},
\] and a dispersion parameter \begin{align*}
\psi
&=
\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\\
&=
\frac{\alpha}{\beta^{2}} \left( \frac{\beta}{\alpha} \right)^{2}
\\
&=
\frac{1}{\alpha}.
\end{align*} We can then define an appropriate observational model by
replacing the location parameter \(\mu\) with the race-entrant baseline
\(\mu_{re}\) for each entrant in a particular race.

\subsubsection{Prior Model}\label{prior-model}

To elevate our observational model to a full Bayesian model we need to
specify a prior model over our model configuration variables. Here we'll
assume that the prior model is built up from independent component prior
models for each parameter.

To avoid unrealistically fast and slow races let's constrain the
baseline finish time to \begin{alignat*}{5}
& 1800 \text{ seconds} &
& \lessapprox &
& \quad\quad\;\; t_{\mathrm{baseline}} &
& \lessapprox &
& \, 5400 \text{ seconds}
\\
& 1800 \text{ seconds} &
& \lessapprox &
& \, \exp(\eta) \cdot 1 \text{ second} \, &
& \lessapprox &
& \, 5400 \text{ seconds}
\\
& 1800 &
& \lessapprox &
& \quad\quad\; \exp(\eta) &
& \lessapprox &
& \, 5400
\\
& \log 1800 &
& \lessapprox &
& \quad\quad\quad\;\;\, \eta &
& \lessapprox &
& \log 5400.
\end{alignat*} We can ensure that 98\% of the prior probability is
contained within these bounds with the prior model \begin{align*}
p( \eta )
&=
\text{normal} \left(
\eta \;\, \bigg| \;\, \frac{\log 5400 + \log 1800}{2},
                        \frac{1}{2.32} \frac{\log 5400 - \log 1800}{2} \right)
\\
&= \text{normal}( \eta \mid 8.045, 0.237).
\end{align*} Note that this prior model doesn't suppress finish times
below 30 minutes and above 90 minutes, just the baseline around which
finish times concentrate. The variation of the gamma observational model
will allow for much smaller and much larger finish times.

Similarly it would be a bit extreme if seed difficulty or entrant skill
modified the baseline by more than a factor of two, \begin{align*}
\frac{1}{2} \lessapprox &\delta \lessapprox 2
\\
\log \frac{1}{2} \lessapprox &\lambda \lessapprox \log 2
\\
- \log 2 \lessapprox &\lambda \lessapprox \log 2.
\end{align*} A reasonable prior that achieves this soft containment is
then \begin{align*}
p( \lambda )
&=
\text{normal} \left(
\lambda \;\, \bigg| \;\, \frac{\log 2 + (-\log 2)}{2},
                         \frac{1}{2.32} \frac{\log 2 - (-\log 2)}{2} \right)
\\
&=
\text{normal} \left(
\lambda \;\, \bigg| \;\, 0, \frac{1}{2.32} \, \log 2\right)
\\
&= \text{normal}( \lambda \mid 0, 0.299).
\end{align*}

Lastly we need to consider the dispersion strength \(\psi\). Here let's
suppress model configurations where the variance would exceed the
squared mean, \begin{align*}
0 \lessapprox
&\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\lessapprox 1
\\
0 \lessapprox & \quad\quad\;\;\;\, \psi \quad\quad\;\;\;\,  \lessapprox 1.
\end{align*} One way to achieve this soft containment is with the prior
model \[
p( \psi )
= \text{half-normal} \left( \psi \;\, \bigg| \;\, 0, \frac{1}{2.57} \right)
= \text{half-normal} \left( \psi \;\, \bigg| \;\, 0, 0.389 \right).
\]

\subsubsection{Anchors}\label{anchors}

Incidentally this simplified model of the data generating process is a
\href{https://betanalpha.github.io/assets/chapters_html/pairwise_comparison_modeling.html}{pairwise
comparison model}. In particular the race seeds and entrants define
bipartide items with the race seed difficulty and entrant skills their
respective qualities. Moreover the location of the finish times is
coupled to these item qualities with a baseline-inducing function.

One advantage of this categorization is that it can motivate productive
model expansions. For example we could model how sensitive different
race seeds are to entrant skill by introducing a discrimination
parameter for each race, \[
\mu_{se}
=
\exp(
\gamma
+ \gamma_{r} \cdot (  \lambda_{\mathrm{difficulty}, r}
                    - \lambda_{\mathrm{skill}, e}) )
\cdot 1 \text{ second}.
\] The smaller \(\gamma_{r}\) is the less sensitive the finish times for
the given race seed will be to the contrast between race seed difficulty
and entrant skill.

Another benefit of this categorization is a recognition of potential
inferential degeneracies and guidance on how to robustify our model to
them. For example because we are using a baseline-inducing function and
the items being compared are bipartide we need to anchor one of each
item type within each connected component to avoid degeneracies.

Interestingly there is more than one connected component here.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}graph\_utility.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}

\NormalTok{cat\_race\_idxs }\OtherTok{\textless{}{-}} \FunctionTok{unlist}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                               \ControlFlowTok{function}\NormalTok{(r)}
                               \FunctionTok{rep}\NormalTok{(r, data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f[r])))}

\NormalTok{cat\_entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_races }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs}

\NormalTok{adj }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{build\_adj\_matrix}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{N\_races }\SpecialCharTok{+}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
\NormalTok{                             data}\SpecialCharTok{$}\NormalTok{N\_entrances\_fs,}
\NormalTok{                             cat\_race\_idxs, cat\_entrant\_idxs)}

\NormalTok{components }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_connected\_components}\NormalTok{(adj)}
\FunctionTok{length}\NormalTok{(components)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 12
\end{verbatim}

That said all but the first connected component are singleton components
consisting of a single entrant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{format\_bipartide\_item }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i) \{}
  \FunctionTok{ifelse}\NormalTok{(i }\SpecialCharTok{\textgreater{}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_race,}
         \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, i }\SpecialCharTok{{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_races),}
         \FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{, i))}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ (c }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(components)) \{}
  \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}Component \%s:}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{  items }\OtherTok{\textless{}{-}} \FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}\%s,\textquotesingle{}}\NormalTok{, }\FunctionTok{sapply}\NormalTok{(components[[c]],}
\NormalTok{                                 format\_bipartide\_item))}
  \FunctionTok{cat}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\FunctionTok{strwrap}\NormalTok{(}\FunctionTok{do.call}\NormalTok{(paste, }\FunctionTok{as.list}\NormalTok{(items)), }\DecValTok{70}\NormalTok{, }\DecValTok{2}\NormalTok{),}
      \AttributeTok{collapse=}\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{))}
  \FunctionTok{cat}\NormalTok{(}\StringTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Component 1:
  Race 1, Entrant 18, Race 2, Entrant 7, Race 3, Entrant 70, Race 6,
Entrant 12, Race 7, Entrant 4, Race 8, Entrant 29, Race 4, Race 5,
Entrant 91, Race 9, Race 10, Entrant 36, Race 16, Entrant 5, Race 12,
Entrant 3, Race 31, Entrant 43, Race 32, Entrant 1, Race 19, Entrant
13, Race 186, Entrant 30, Race 11, Entrant 28, Race 15, Entrant 6,
Race 51, Entrant 17, Race 27, Entrant 57, Race 17, Entrant 64, Race
22, Entrant 44, Race 20, Entrant 88, Race 24, Entrant 34, Race 23,
Entrant 65, Race 14, Race 33, Entrant 16, Race 64, Entrant 26, Race
21, Entrant 45, Race 30, Entrant 14, Entrant 58, Race 25, Entrant 60,
Race 29, Entrant 19, Race 37, Race 42, Entrant 94, Race 28, Entrant
68, Race 36, Entrant 96, Race 50, Entrant 107, Race 39, Entrant 90,
Race 13, Entrant 69, Race 18, Race 63, Entrant 2, Race 34, Entrant
95, Race 38, Race 58, Entrant 31, Race 74, Entrant 61, Race 75,
Entrant 100, Race 26, Entrant 73, Race 61, Entrant 51, Race 48,
Entrant 49, Race 49, Race 52, Entrant 24, Race 45, Entrant 82, Race
80, Entrant 22, Race 76, Entrant 23, Race 87, Entrant 48, Race 55,
Entrant 78, Race 43, Entrant 79, Entrant 83, Race 105, Entrant 55,
Race 90, Race 93, Entrant 81, Race 53, Race 84, Entrant 98, Race 71,
Race 102, Entrant 8, Race 86, Entrant 93, Race 88, Race 91, Entrant
105, Race 59, Entrant 20, Race 172, Entrant 71, Race 110, Entrant 42,
Race 103, Entrant 72, Race 68, Race 69, Race 97, Entrant 59, Race 89,
Race 92, Race 94, Race 104, Race 107, Race 117, Race 132, Race 139,
Race 140, Entrant 25, Race 143, Entrant 35, Race 62, Race 101, Race
106, Entrant 10, Race 127, Race 128, Entrant 62, Race 147, Entrant 9,
Race 154, Entrant 41, Entrant 97, Entrant 104, Race 155, Race 157,
Entrant 86, Entrant 74, Race 142, Entrant 32, Entrant 46, Race 149,
Entrant 92, Race 148, Entrant 11, Entrant 39, Entrant 99, Race 56,
Entrant 106, Race 179, Race 141, Entrant 101, Race 123, Entrant 89,
Race 160, Race 165, Race 171, Entrant 50, Race 173, Race 183, Race
184, Race 188, Race 192, Race 98, Race 112, Race 115, Race 134, Race
136, Entrant 75, Race 137, Race 166, Race 174, Race 177, Race 191,
Entrant 15, Race 65, Race 66, Entrant 33, Race 72, Race 73, Race 78,
Race 82, Race 99, Race 100, Race 111, Race 121, Race 151, Race 152,
Race 169, Race 95, Race 96, Entrant 40, Race 118, Race 120, Race 124,
Race 125, Race 126, Race 130, Race 156, Entrant 21, Entrant 52, Race
162, Race 114, Race 133, Race 144, Race 185, Race 77, Race 81, Race
60, Race 145, Entrant 76, Race 46, Race 122, Race 161, Race 176, Race
178, Race 54, Race 70, Race 158, Race 159, Race 40, Race 41, Race 44,
Race 47, Race 67, Entrant 84, Race 83, Race 85, Race 135, Race 164,
Entrant 54, Race 35, Race 79, Race 180, Race 131, Race 138, Race 57,
Race 108, Race 113, Race 150, Race 116, Race 129, Race 168, Race 190,
Entrant 63, Race 182, Race 153, Race 170, Race 189, Entrant 66, Race
109, Race 146, Race 181, Entrant 85, Race 119, Race 175, Race 187,
Race 163, Entrant 102, Race 167,

Component 2:
  Entrant 27,

Component 3:
  Entrant 37,

Component 4:
  Entrant 38,

Component 5:
  Entrant 47,

Component 6:
  Entrant 53,

Component 7:
  Entrant 56,

Component 8:
  Entrant 67,

Component 9:
  Entrant 77,

Component 10:
  Entrant 80,

Component 11:
  Entrant 87,

Component 12:
  Entrant 103,
\end{verbatim}

All of these isolated entrants have never finished a race, with their
participation limited to forfeits.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (component }\ControlFlowTok{in}\NormalTok{ components) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(component) }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    e }\OtherTok{\textless{}{-}}\NormalTok{ component[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_races}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \%s: \%i finished races}\SpecialCharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{        e, N\_entrant\_f\_races[e]))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 27: 0 finished races
Entrant 37: 0 finished races
Entrant 38: 0 finished races
Entrant 47: 0 finished races
Entrant 53: 0 finished races
Entrant 56: 0 finished races
Entrant 67: 0 finished races
Entrant 77: 0 finished races
Entrant 80: 0 finished races
Entrant 87: 0 finished races
Entrant 103: 0 finished races
\end{verbatim}

When modeling finish times we need to anchor only a single race seed and
entrant. Here we'll anchor the most popular race seed and most prolific
entrant.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data}\SpecialCharTok{$}\NormalTok{anchor\_race\_idx }\OtherTok{\textless{}{-}}
  \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f }\SpecialCharTok{==} \FunctionTok{max}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_f))}

\NormalTok{data}\SpecialCharTok{$}\NormalTok{anchor\_entrant\_idx }\OtherTok{\textless{}{-}}
  \FunctionTok{which}\NormalTok{(N\_entrant\_f\_races }\SpecialCharTok{==} \FunctionTok{max}\NormalTok{(N\_entrant\_f\_races))}
\end{Highlighting}
\end{Shaded}

The last thing we need to do is push forward our normal prior model over
the race difficulties and entrant skills, \[
\text{normal}( \lambda \mid 0, \log 2 \, / \, 2.32)
\] to an appropriately inflated prior model over the relative
difficulties and entrant skills, \[
\text{normal}( \delta \mid 0, \sqrt{2} \cdot \log 2 \, / \, 2.32).
\]

\subsubsection{Inferential Computation}\label{inferential-computation}

We can now implement our full Bayesian model as a Stan program, plug in
the observed data, and give Stan's Hamiltonian Monte Carlo sampler a
chance at exploring the posterior distribution.

\begin{codelisting}

\caption{\texttt{model1.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of gamma family}
  \DataTypeTok{real}\NormalTok{ gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ gamma\_lpdf(x | inv(psi), inv(mu * psi));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ gamma\_rng(inv(psi), inv(mu * psi));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Total number of entrant finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Relative seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties\_free;}

  \CommentTok{// Relative entrant skills}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills\_free;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Gamma dispersion configuration}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties;}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_difficulties\_free[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    = rel\_difficulties\_free[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_skills\_free[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    = rel\_skills\_free[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_difficulties\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} rel\_skills \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_skills\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

  \CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);}

  \CommentTok{// Observational model}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(  eta}
\NormalTok{                    + rel\_difficulties[r]}
\NormalTok{                    {-} rel\_skills[entrant\_idx]);}
\NormalTok{      entrant\_f\_times[n] \textasciitilde{} gamma\_md(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}

    \CommentTok{// Finish time predictions conditioned on not forfeiting}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(  eta}
\NormalTok{                    + rel\_difficulties[r]}
\NormalTok{                    {-} rel\_skills[entrant\_idx]);}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = gamma\_md\_rng(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model1.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The empirical effective sample size warnings suggest some nontrivial
autocorrelations, especially in the baseline \(\eta\), but nothing large
enough to compromise the faithfulness of Markov chain Monte Carlo
integration.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics1 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples1 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
eta:
  Chain 1: hat{ESS} (34.284) is smaller than desired (100).
  Chain 2: hat{ESS} (58.063) is smaller than desired (100).
  Chain 3: hat{ESS} (52.912) is smaller than desired (100).
  Chain 4: hat{ESS} (64.830) is smaller than desired (100).

rel_skills_free[64]:
  Chain 1: hat{ESS} (95.800) is smaller than desired (100).


Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

\subsubsection{Posterior Retrodictive
Checks}\label{posterior-retrodictive-checks}

There are a lot of summary statistics that we might consider for our
visual posterior retrodictive checks. Indeed we explored some candidates
in \hyperref[sec:data-exploration]{Section 3}.

For example we could use a histogram summary statistic that aggregates
the finish times across all races. Here we see a pretty strong
retrodictive tension, with the observed finish times exhibiting stronger
skewness than what the posterior predictive distribution can
accommodate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples1, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-17-1.pdf}

This tension could be due to an inadequacy of the gamma observational
model, but it could also be a consequence of poorly modeling the
heterogeneity in seed difficulties and entrant skills. One way to
explore these possibilities is to separate the histogram summary
statistic by race and entrant.

Here there doesn't seem to be any substantial retrodictive tension in
the finish times for a few arbitrarily selected races.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 65 predictive values (0.1%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 100 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-18-1.pdf}

Similarly the finish time behaviors for a few spot-checked entrants are
consistent between the observed data and our posterior predictions. One
might argue that the observed behavior for entrant 93 is slightly
heavier-tailed than the posterior predictions, but the disagreement is
relatively weak.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples1, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 3 predictive values (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 23 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-19-1.pdf}

If we really wanted to be thorough then we would need to examine the
behavior of the hundreds of finish time histograms across all of the
individual races and all of the individual entrants. Based on the
reasonable behavior of the few spot checks that we've performed here,
however, let's see if changing the observational model addresses the
issue.

\subsection{Model 2}\label{model-2}

The gamma family of probability density functions are naturally
complemented with the inverse gamma family of probability density
functions. Because the gamma probability density functions exhibit
heavier tails towards zero and lighter tails towards infinity their
\emph{peaks} skew towards larger values. On the other hand the inverse
gamma probability density functions exhibit lighter tails towards zero
and heavier tails towards infinity, resulting in \emph{peaks} that skew
towards smaller values. This conveniently contrasting behavior might be
exactly what we need to address the retrodictive tension in our first
model.

In order to build an inverse gamma observational model we need to
engineer a location-dispersion parameterization. The inverse gamma
family, like the gamma family, is typically parameterized in terms of a
shape parameter \(\alpha\) and a scale parameter \(\beta\) but we can
also parameterize the family in terms of a location parameter \[
\mu = \text{mean}(\alpha, \beta) = \frac{\beta}{\alpha - 1}
\] and a dispersion parameter \begin{align*}
\psi
&=
\frac{ \text{variance}(\alpha, \beta) }{ \text{mean}^{2}(\alpha, \beta) }
\\
&=
\frac{1}{\alpha - 2} \left( \frac{ \beta }{ \alpha - 1} \right)^{2}
\left( \frac{ \alpha - 1 }{ \beta } \right)^{2}
\\
&=
\frac{1}{\alpha - 2}.
\end{align*}

Let's try swapping the gamma observational model with an inverse gamma
observational model.

\begin{codelisting}

\caption{\texttt{model2.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Total number of entrant finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Relative seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties\_free;}

  \CommentTok{// Relative entrant skills}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills\_free;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Inverse gamma dispersion configuration}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties;}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_difficulties\_free[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    = rel\_difficulties\_free[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_skills\_free[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    = rel\_skills\_free[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_difficulties\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} rel\_skills \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_skills\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

  \CommentTok{// 0 \textless{}\textasciitilde{} psi \textless{}\textasciitilde{} 1}
\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);}

  \CommentTok{// Observational model}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(  eta}
\NormalTok{                    + rel\_difficulties[r]}
\NormalTok{                    {-} rel\_skills[entrant\_idx]);}
\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}

    \CommentTok{// Finish time predictions conditioned on not forfeiting}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(  eta}
\NormalTok{                    + rel\_difficulties[r]}
\NormalTok{                    {-} rel\_skills[entrant\_idx]);}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model2.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The diagnostics again suggest some larger autocorrelations for the
baseline \(\eta\) but nothing too problematic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics2 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples2 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
eta:
  Chain 1: hat{ESS} (44.072) is smaller than desired (100).
  Chain 2: hat{ESS} (73.652) is smaller than desired (100).
  Chain 3: hat{ESS} (93.127) is smaller than desired (100).


Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

It looks like this tweak to our model may have done the trick. The
observed and posterior predictive behavior of the aggregate finish time
histogram is a bit more consistent than it was in our first model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples2, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-22-1.pdf}

The retrodictive agreement in the individual race finish time histograms
is similar to what we saw above. In particular no new retrodictive
tensions have arisen.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 84 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 137 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 7 predictive values (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-23-1.pdf}

Interestingly the heavier tail of the inverse gamma family appears to
allow the posterior predictive behavior for entrant 93 to spread out
further and better match the observed behavior.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples2, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 6 predictive values (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 18 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-24-1.pdf}

With no immediate reason to doubt our modeling assumptions we can
finally move on to investigating our posterior inferences. The marginal
posterior distributions for \(\eta\) and \(\psi\) look reasonable, with
both strongly contracting within the prior model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"eta"}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"psi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-25-1.pdf}

While the values of the relative seed difficulties all seem reasonable
there does appear to be an unexpected pattern across the races.
Initially the difficulties systematically decay before flatting out.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-26-1.pdf}

On the other hand the relative entrant skills exhibit both reasonable
values and no systematic patterns.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-27-1.pdf}

Let's go back to the relative difficulties and consider why we might see
a pattern like that. Because the seeds for each race are ordered by the
time at which the race occurred the pattern we see here may be due to a
systematic change in seed difficulty over time.

One possibility is that the randomized maps are actually getting easier
to complete. Another possibility is that our inferences for the seed
difficulties are actually compensating for other time-dependent
behaviors in these races that the model cannot otherwise accommodate.
For example if the entire racing community was gradually getting better
at the game then the entrant skills would improve with time. Because our
model assumes static skills, however, the model could contort itself and
absorb this time dependence into decreasing seed difficulties.

In order to distinguish between these possible hypotheses let's dive
into this inferential behavior a bit deeper. If the MapRando code were
static then it would be natural to assume that the seed difficulties
scatter around some constant baseline. The MapRando code, however, is
not static and has in fact undergone consistent develop throughout 2024.
Fortunately the code version of each seed is included in our data, and
we can visualize the MapRando development by overlaying the difficulties
with the version numbers.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{)}

\NormalTok{text\_versions }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"105"}\NormalTok{, }\StringTok{"108"}\NormalTok{, }\StringTok{"109"}\NormalTok{, }\StringTok{"111"}\NormalTok{,}
                   \StringTok{"112 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{(DEV}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{)"}\NormalTok{, }\StringTok{"112"}\NormalTok{, }\StringTok{"113 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{(DEV}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{)"}\NormalTok{, }\StringTok{"113"}\NormalTok{)}
\NormalTok{num\_versions }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{105}\NormalTok{, }\DecValTok{108}\NormalTok{, }\DecValTok{109}\NormalTok{, }\DecValTok{111}\NormalTok{, }\FloatTok{111.5}\NormalTok{, }\DecValTok{112}\NormalTok{, }\FloatTok{112.5}\NormalTok{, }\DecValTok{113}\NormalTok{)}
\NormalTok{versions }\OtherTok{\textless{}{-}}\NormalTok{ race\_info}\SpecialCharTok{$}\NormalTok{versions}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(text\_versions)) \{}
\NormalTok{  versions }\OtherTok{\textless{}{-}} \FunctionTok{gsub}\NormalTok{(text\_versions[n], num\_versions[n], versions)}
\NormalTok{\}}
\NormalTok{versions }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(versions)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{new=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\DecValTok{0}\NormalTok{, }\AttributeTok{type=}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{, }\AttributeTok{axes=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{""}\NormalTok{, }\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, data}\SpecialCharTok{$}\NormalTok{N\_races),}
     \AttributeTok{ylab =} \StringTok{""}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{104}\NormalTok{, }\DecValTok{114}\NormalTok{))}

\NormalTok{plot\_xs }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{c}\NormalTok{(r }\SpecialCharTok{{-}} \FloatTok{0.5}\NormalTok{, r }\SpecialCharTok{+} \FloatTok{0.5}\NormalTok{))}
\FunctionTok{dim}\NormalTok{(plot\_xs) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2} \SpecialCharTok{*}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{N\_races)}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  idx1 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ r }\SpecialCharTok{{-}} \DecValTok{1}
\NormalTok{  idx2 }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ r}
  \FunctionTok{lines}\NormalTok{(plot\_xs[}\DecValTok{1}\NormalTok{, idx1}\SpecialCharTok{:}\NormalTok{idx2], }\FunctionTok{rep}\NormalTok{(versions[r], }\DecValTok{2}\NormalTok{),}
        \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{mtext}\NormalTok{(}\StringTok{"Version"}\NormalTok{, }\AttributeTok{side=}\DecValTok{4}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{line=}\DecValTok{3}\NormalTok{, }\AttributeTok{las=}\DecValTok{0}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{4}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{104}\NormalTok{, }\DecValTok{114}\NormalTok{), }\AttributeTok{las=}\DecValTok{1}\NormalTok{,}
     \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal, }\AttributeTok{col.axis=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid\_teal)}

\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\FloatTok{16.5}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\FloatTok{87.5}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-28-1.pdf}

All of the prominent changes in seed difficulty over time seem to neatly
line up with the transitions from one version to another. In hindsight
this is completely reasonable: each version improves the randomization
logic to be more consistent and easier for players to manage, especially
in the earlier versions.

What about the hypothesis of improving entrant skills? If entrant skills
were improving then it would be reasonable to expect systematic patterns
between entrant skill and their overall experience with MapRando. While
we do not have access to any exact quantification of experience we can
consider proxies, such as the total number of race entrances. In
particular while entrants might play MapRando, and gain experience,
outside of official races that play time is likely to at least somewhat
scale with the number of race entrances.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total\_entrances }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs)}
\NormalTok{sorted\_entrances }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{sort}\NormalTok{(total\_entrances))}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(sorted\_entrances}\SpecialCharTok{$}\NormalTok{Var1,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples2, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrants Ordered By Total Entrances"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{sorted\_entrances}\SpecialCharTok{$}\NormalTok{Var1,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-29-1.pdf}

The most striking pattern that we see is that the \emph{uncertainty} in
the entrant skill inferences decreases with increasing participation,
which is just a consequence of having more data from which to learn.
Beyond the decreasing uncertainty there might also be a mild increase in
skill for the most experienced players.

That said this increase is not necessarily tied to increased experience.
For example entrant skills might be fixed with more skilled players just
enjoying the MapRando races more and hence playing more.

In order to distinguish between these possibilities we need to start
investigating how the behavior for a single entrant changes with
increasing experience. If entrant skills increased enough, for instance,
then we would see the finish times for a particular entrant
systematically decrease with an increasing number of entrances.

Here let's look at entrant 65.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\NormalTok{completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  N\_previous\_races }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(cum\_completed\_races)}

\NormalTok{  entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[entrant\_idxs]) \{}
\NormalTok{    entrant\_idx }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[entrant\_idxs] }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{    time }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r] }\SpecialCharTok{+}\NormalTok{ entrant\_idx }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}

    \ControlFlowTok{if}\NormalTok{ (N\_previous\_races }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(cum\_completed\_races,}
\NormalTok{                               cum\_completed\_races[N\_previous\_races] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{    completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(completion\_times, time)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \ControlFlowTok{if}\NormalTok{ (N\_previous\_races }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      cum\_completed\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(cum\_completed\_races,}
\NormalTok{                               cum\_completed\_races[N\_previous\_races])}
\NormalTok{      completion\_times }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(completion\_times,}
\NormalTok{                            completion\_times[N\_previous\_races])}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(cum\_completed\_races, completion\_times }\SpecialCharTok{/} \DecValTok{60}\NormalTok{,}
     \AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{cex=}\FloatTok{1.0}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
     \AttributeTok{xlab=}\StringTok{"Total Entrances"}\NormalTok{,}
     \AttributeTok{ylab=}\StringTok{"Completion Time (minutes)"}\NormalTok{,}
     \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-30-1.pdf}

While there might be a small reduction in the \emph{variation} of finish
times there doesn't seem to be any systematic increase or decrease in
the mean. That's not to say that skills don't improve, just that they're
not improving strongly enough to manifest in this particular
visualization.

Overall the development of the MapRando code offers a satisfying
explanation for the patterns we see in the inferred seed difficulties.
That said it's always helpful to keep the other hypotheses in mind,
especially if we are able to collect more data in the future.

\subsection{Model 3}\label{model-3}

For our next model iteration let's consider forfeits. The danger with
ignoring forfeits is that if the forfeit probability is coupled with
entrant skill then inferences from the finish times alone will give us a
biased view of those skills.

One possible assumption is that forfeits are completely random. For
example entrants could forfeit mostly due to unexpected events that
arise during each race that have nothing to do with their performance.
In this case we could still extract information from the forfeit times
because we can lower bound what the finish time would have been,
\begin{align*}
p(t_{\mathrm{forfeit}} \mid \mu_{se}, \psi)
&=
\pi( \, [ t_{\mathrm{forfeit}}, \infty ) \, \mid \mu_{se}, \psi)
\\
&=
\int_{0}^{t_{\mathrm{forfeit}}} \mathrm{d} t \,
\text{inv-gamma}(t \mid \mu_{se}, \psi)
\\
&=
1 - \Pi_{\text{inv-gamma}}(t_{\mathrm{forfeit}} \mid \mu_{se}, \psi).
\end{align*} Unfortunately while forfeit times are recorded they are
difficult to programmatically access from
\texttt{https://racetime.gg/smr}.

Forfeiting, however, is unlikely to be completely random. Entrants are
more likely to forfeit when they're frustrated by the overall
difficulty, for example when they get lost in a complex map layout or
die at an inopportune point and lose too much progress. This suggests
that \(p(t_{\mathrm{forfeit}})\) should depend on the contrast between
seed difficulty and entrant skill, \[
p(t_{\mathrm{forfeit}} \mid \lambda_{\mathrm{difficulty}, s},
                            \lambda_{\mathrm{skill}, e})
=
f(\lambda_{\mathrm{difficulty}, s} - \lambda_{\mathrm{skill}, e}).
\]

To start let's assume a logistic model, \[
p(t_{\mathrm{forfeit}} \mid \lambda_{\mathrm{difficulty}, s},
                            \lambda_{\mathrm{skill}, e},
                            \kappa_{e}, \beta_{e})
= \
\mathrm{logistic}( \beta_{e} \cdot (
                   (   \lambda_{\mathrm{difficulty}, s}
                     - \lambda_{\mathrm{skill}, e})
                    - \kappa_{e}     ) ),
\] where \(\kappa_{e}\) quantifies the threshold contrast where an
entrant achieves a forfeit probability of \(\frac{1}{2}\) and
\(\beta_{e}\) quantifies how sensitive the forfeit probability is to the
difference around this threshold. In order to ensure that a larger
contrast always results in a higher forfeit we'll need to assume that
\(\beta_{e}\) is limited to only positive values.

Note that this forfeit model is \emph{another} pairwise comparison
model! This time the contrasting item qualities are coupled to the
forfeit probability with a discrimination parameter \(\beta_{e}\) in
addition to a baseline parameter \(\kappa_{e}\).

Beyond this functional form it's not straightforward to elicit domain
expertise about reasonable values for \(\kappa_{e}\) and \(\beta_{e}\).
Here we'll take a more heuristic prior model that just constrains
\(\kappa_{e}\) and \(\beta_{e}\) below five in order to avoid saturating
the outputs of the logistic function too quickly.

Lastly once we explicitly model forfeits we are in a position to predict
forfeits. This in turn provides new opportunities for retrodictive check
summary statistics. In particular here we will consider the total number
of forfeits in each race.

\begin{codelisting}

\caption{\texttt{model3.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who forfeit and did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting forfeited entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}

  \CommentTok{// Forfeited entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Relative seed difficulties}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties\_free;}

  \CommentTok{// Relative entrant skills}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills\_free;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{real}\NormalTok{ rel\_difficulties;}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_difficulties\_free[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    = rel\_difficulties\_free[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_skills\_free[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    = rel\_skills\_free[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} difficulties \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_difficulties\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

  \CommentTok{// {-}sqrt(2) * log(2) \textless{}\textasciitilde{} rel\_skills \textless{}\textasciitilde{} +sqrt(2) * log(2)}
\NormalTok{  rel\_skills\_free \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}

\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);   }\CommentTok{//  0 \textless{}\textasciitilde{} psi    \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{); }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);  }\CommentTok{//  0 \textless{}\textasciitilde{} betas  \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_N\_entrants\_dnf\_pred = rep\_array(}\DecValTok{0}\NormalTok{, N\_races);}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who forfeited}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}

    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

      \CommentTok{// Finish time prediction conditioned on not forfeiting}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}

      \CommentTok{// Forfeit prediction}
\NormalTok{      race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \CommentTok{// Forfeit prediction}
\NormalTok{        race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model3.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A few new warning have arisen suggesting that some of the \(\kappa_{e}\)
exhibit heavier tails.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics3 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples3 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
eta:
  Chain 2: hat{ESS} (44.243) is smaller than desired (100).
  Chain 3: hat{ESS} (42.969) is smaller than desired (100).

rel_difficulties_free[77]:
  Chain 2: hat{ESS} (86.897) is smaller than desired (100).
  Chain 3: hat{ESS} (89.644) is smaller than desired (100).

rel_difficulties_free[102]:
  Chain 2: hat{ESS} (90.656) is smaller than desired (100).

rel_difficulties_free[117]:
  Chain 2: hat{ESS} (97.224) is smaller than desired (100).
  Chain 3: hat{ESS} (99.676) is smaller than desired (100).

rel_difficulties_free[134]:
  Chain 2: hat{ESS} (90.349) is smaller than desired (100).

rel_difficulties_free[142]:
  Chain 3: hat{ESS} (98.933) is smaller than desired (100).

kappas[6]:
  Chain 3: Right tail hat{xi} (0.251) exceeds 0.25.

kappas[7]:
  Chain 1: Left tail hat{xi} (0.305) exceeds 0.25.

kappas[44]:
  Chain 2: Right tail hat{xi} (0.307) exceeds 0.25.

kappas[61]:
  Chain 2: Left tail hat{xi} (0.283) exceeds 0.25.

kappas[94]:
  Chain 1: Right tail hat{xi} (0.274) exceeds 0.25.

kappas[98]:
  Chain 1: Both left and right tail hat{xi}s (0.354, 0.293) exceed 0.25.
  Chain 2: Left tail hat{xi} (0.349) exceeds 0.25.
  Chain 3: Left tail hat{xi} (0.343) exceeds 0.25.
  Chain 4: Both left and right tail hat{xi}s (0.446, 0.323) exceed 0.25.


Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

We can confirm this by examining the corresponding marginal posterior
behaviors. That said these heavy tail warnings are of concern only if we
attempt to estimate the expectation of the corresponding parameter
functions, which will not in this analysis.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}kappas[98]\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"kappas[98]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-33-1.pdf}

The retrodictive agreement between the observed and posterior predictive
finish time histograms continues.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples3, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-34-1.pdf}

Now we can also consider the number of forfeits in each race.
Fortunately the behavior of this statistic is also reasonably
consistent.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-35-1.pdf}

To make the comparison more clear we can always visualize the residuals
and then compare to zero.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{residual=}\ConstantTok{TRUE}\NormalTok{,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-36-1.pdf}

Finally the finish time histograms separated by selected races and
entrants also show no signs of retrodictive tension.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 85 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 160 predictive values (0.3%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 5 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-37-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples3, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 8 predictive values (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 19 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-38-1.pdf}

Without any concerns about our modeling assumptions we can move on to
examining the resulting posterior inferences. Inferences for the
existing parameters are at least superficially similar to those from the
second model; we'll make a more direct comparison in
\hyperref[sec:inf-comp]{Section 4.5}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"eta"}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"psi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-39-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-40-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Skill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-41-1.pdf}

More relevant for this latest model iteration are the posterior
inferences for the new, forfeit-related parameters. Overall the
uncertainties are relatively large but we can pick out a few exceptional
behaviors

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Forfeit Threshold"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-42-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}betas[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples3, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Forfeit Scale"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-43-1.pdf}

For example posterior inferences of the forfeit thresholds for entrants
37 and 38 both concentrate on negative values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{37}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{38}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-44-1.pdf}

Both of these entrants forfeited every race they entered.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summarize\_entrant }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
\NormalTok{  N }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_f\_races[e] }\SpecialCharTok{+}\NormalTok{ N\_entrant\_dnf\_races[e]}
\NormalTok{  Nf }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_f\_races[e]}
\NormalTok{  Ndnf }\OtherTok{\textless{}{-}}\NormalTok{ N\_entrant\_dnf\_races[e]}

  \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Entrant \%i}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, e))}
  \ControlFlowTok{if}\NormalTok{ (N }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i total entrances}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, N))}
  \ControlFlowTok{else}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i total entrance}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, N))}

  \ControlFlowTok{if}\NormalTok{ (Nf }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i finishes (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Nf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Nf }\SpecialCharTok{/}\NormalTok{ N))}
  \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (Nf }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i finish (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Nf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Nf }\SpecialCharTok{/}\NormalTok{ N))}

  \ControlFlowTok{if}\NormalTok{ (Ndnf }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i forfeits (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Ndnf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Ndnf }\SpecialCharTok{/}\NormalTok{ N))}
  \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (Ndnf }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"  \%i forfeit (\%.1f\%\%)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, Ndnf, }\DecValTok{100} \SpecialCharTok{*}\NormalTok{ Ndnf }\SpecialCharTok{/}\NormalTok{ N))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(}\DecValTok{37}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 37
  2 total entrances
  2 forfeits (100.0%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(}\DecValTok{38}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 38
  2 total entrances
  2 forfeits (100.0%)
\end{verbatim}

On the other hand posterior inferences of the forfeit threshold for
entrant 65 concentrates on positive values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-47-1.pdf}

This entrant forfeited only once out of 64 total entrances.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 65
  64 total entrances
  63 finishes (98.4%)
  1 forfeit (1.6%)
\end{verbatim}

Moreover that forfeit occurred for a particularly difficult seed,
pushing the consistent forfeit threshold behaviors to larger values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
  \ControlFlowTok{if}\NormalTok{ (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf[r] }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\ControlFlowTok{next}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs[idxs])}
\NormalTok{    dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(dnf\_races, r)}
\NormalTok{\}}

\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, dnf\_races[}\DecValTok{1}\NormalTok{], }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{25}\NormalTok{, }\AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Relative Difficulty"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Race\textquotesingle{}}\NormalTok{, dnf\_races[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-49-1.pdf}

Finally the posterior inferences of the forfeit threshold for entrant 44
mostly concentrate on values between \(0\) and \(1\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{44}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}kappas[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\StringTok{"Forfeit Threshold"}\NormalTok{,}
                                \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{\textquotesingle{}Entrant\textquotesingle{}}\NormalTok{, e))}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-50-1.pdf}

While entrant 44 finishes most of their entrances forfeits are not
uncommon.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 44
  71 total entrances
  56 finishes (78.9%)
  15 forfeits (21.1%)
\end{verbatim}

This higher propensity to forfeit suppresses larger values of the
forfeit threshold.

Overall our posterior inferences for the forfeit behavior are
reasonable, but the relative scarcity of forfeits prevents us from
resolving that behavior with too much precision.

\subsection{Model 4}\label{model-4}

A natural extension of the last model is to couple the behavior across
individual race seeds and entrants. This would allow data to be shared
across entrances and potentially reducing inferential uncertainties,
especially for races and entrants with few entrances to inform them
directly. In particular if our domain expertise about these behaviors is
exchangeable then we can couple them together with
\href{https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html}{hierarchical
models}. As a side benefit we can also use the inferred hierarchical
population behavior to make inferences and predictions about new,
hypothetical seeds and entrants.

Because the MapRando version distinguishes some seeds from each other
not all of the seed difficulties are exchangeable. That said we don't
have any information to discriminate between the seeds \emph{within} a
version, suggesting conditional exchangeabilty. In other words we can
couple the seed difficulties within each MapRando version together into
separate hierarchical models.

For programmatic convenience we'll just need to convert the version
numbers into sequential indices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniq\_versions }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{versions)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(uniq\_versions)}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{version\_idxs }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{factor}\NormalTok{(race\_info}\SpecialCharTok{$}\NormalTok{versions,}
                                       \AttributeTok{levels=}\NormalTok{uniq\_versions,}
                                       \AttributeTok{labels=}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions))}
\end{Highlighting}
\end{Shaded}

On the other hand we don't have any prior information capable of
discriminating between the entrants, at least not without doing
additional research into their experience with Super Metroid® in general
and MapRando in particular. Consequently all of the entrant behaviors
are exchangeable with each other and can be captured with a single
hierarchy. For simplicity I will couple only the entrant skills
together, leaving the heterogeneous entrant forfeit behaviors
independent of each other.

Because the relative seed difficulties and entrant skills are modeled
with one-dimensional, and unconstrained, real values we can reach for
the standard normal hierarchical model to start. All we need then to
implement the model is a parameterization of the individual parameters
in each hierarchy. Here let's start with a monolithic non-centered
parameterizations for all of the hierarchies, hoping that the large
number of seeds and entrants will result in strong enough regularization
to suppress any problematic degeneracies. In the worst case our
computational diagnostics will indicate if we need to consider more
sophisticated parameterizations.

\begin{codelisting}

\caption{\texttt{model4a.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who forfeit and did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting forfeited entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}

  \CommentTok{// Forfeited entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs;}

  \CommentTok{// MapRando versioning}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_versions;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_versions\textgreater{} version\_idxs;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Non{-}centered relative seed difficulties}
  \DataTypeTok{vector}\NormalTok{[N\_races {-} }\DecValTok{1}\NormalTok{] rel\_difficulties\_free\_tilde;}

  \CommentTok{// Relative eed difficulty population configuration}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] mu\_rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] tau\_rel\_difficulties;}

  \CommentTok{// Non{-}centered relative entrant skills}
  \DataTypeTok{vector}\NormalTok{[N\_entrants {-} }\DecValTok{1}\NormalTok{] rel\_skills\_free\_tilde;}

  \CommentTok{// Relative entrant skill population configuration}
  \DataTypeTok{real}\NormalTok{ mu\_rel\_skills;}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} tau\_rel\_skills;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \CommentTok{// Center the non{-}centered relative difficulties}
  \CommentTok{// and skills while inserting the anchors}
  \DataTypeTok{vector}\NormalTok{[N\_races] rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{[N\_entrants] rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =   mu\_rel\_skills}
\NormalTok{      +   tau\_rel\_skills}
\NormalTok{        * rel\_skills\_free\_tilde[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    =   mu\_rel\_skills}
\NormalTok{      +   tau\_rel\_skills}
\NormalTok{        * rel\_skills\_free\_tilde[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

\NormalTok{  rel\_difficulties\_free\_tilde \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  mu\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  rel\_skills\_free\_tilde \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  mu\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);   }\CommentTok{//  0 \textless{}\textasciitilde{} psi    \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{); }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);  }\CommentTok{//  0 \textless{}\textasciitilde{} betas  \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_N\_entrants\_dnf\_pred = rep\_array(}\DecValTok{0}\NormalTok{, N\_races);}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who forfeited}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}

    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

      \CommentTok{// Finish time prediction conditioned on not forfeiting}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}

      \CommentTok{// Forfeit prediction}
\NormalTok{      race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \CommentTok{// Forfeit prediction}
\NormalTok{        race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model4a.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We don't see any of the tell-tale signs of problematic hierarchical
geometries, such as divergences and E-FMI warnings, but the persistent
empirical effective sample size warnings across across the non-centered
entrant skill parameters suggest that a centered parameterization of the
entrant skill hierarchy might perform better.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\_tilde\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\_tilde\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
rel_skills_free_tilde[4]:
  Chain 3: hat{ESS} (78.199) is smaller than desired (100).
  Chain 4: hat{ESS} (98.670) is smaller than desired (100).

rel_skills_free_tilde[5]:
  Chain 3: hat{ESS} (70.555) is smaller than desired (100).

rel_skills_free_tilde[12]:
  Chain 3: hat{ESS} (82.799) is smaller than desired (100).

rel_skills_free_tilde[16]:
  Chain 3: hat{ESS} (83.127) is smaller than desired (100).

rel_skills_free_tilde[17]:
  Chain 3: hat{ESS} (80.187) is smaller than desired (100).

rel_skills_free_tilde[26]:
  Chain 3: hat{ESS} (76.101) is smaller than desired (100).

rel_skills_free_tilde[43]:
  Chain 3: hat{ESS} (86.035) is smaller than desired (100).
  Chain 4: hat{ESS} (91.771) is smaller than desired (100).

rel_skills_free_tilde[44]:
  Chain 3: hat{ESS} (76.720) is smaller than desired (100).

rel_skills_free_tilde[54]:
  Chain 3: hat{ESS} (58.138) is smaller than desired (100).

rel_skills_free_tilde[56]:
  Chain 4: hat{ESS} (96.016) is smaller than desired (100).

rel_skills_free_tilde[57]:
  Chain 3: hat{ESS} (64.781) is smaller than desired (100).
  Chain 4: hat{ESS} (86.086) is smaller than desired (100).

rel_skills_free_tilde[59]:
  Chain 3: hat{ESS} (72.204) is smaller than desired (100).
  Chain 4: hat{ESS} (93.851) is smaller than desired (100).

rel_skills_free_tilde[64]:
  Chain 3: hat{ESS} (58.798) is smaller than desired (100).
  Chain 4: hat{ESS} (93.856) is smaller than desired (100).

rel_skills_free_tilde[89]:
  Chain 3: hat{ESS} (71.703) is smaller than desired (100).
  Chain 4: hat{ESS} (91.745) is smaller than desired (100).

rel_skills_free_tilde[90]:
  Chain 3: hat{ESS} (83.120) is smaller than desired (100).

rel_skills_free_tilde[92]:
  Chain 3: hat{ESS} (86.610) is smaller than desired (100).

rel_skills_free_tilde[93]:
  Chain 3: hat{ESS} (77.070) is smaller than desired (100).

rel_skills_free_tilde[94]:
  Chain 3: hat{ESS} (75.684) is smaller than desired (100).

rel_skills_free_tilde[95]:
  Chain 3: hat{ESS} (55.985) is smaller than desired (100).
  Chain 4: hat{ESS} (98.756) is smaller than desired (100).

rel_skills_free_tilde[99]:
  Chain 3: hat{ESS} (88.862) is smaller than desired (100).

rel_skills_free_tilde[104]:
  Chain 3: hat{ESS} (81.761) is smaller than desired (100).

mu_rel_skills:
  Chain 3: hat{ESS} (86.111) is smaller than desired (100).
  Chain 4: hat{ESS} (97.419) is smaller than desired (100).

kappas[31]:
  Chain 3: Left tail hat{xi} (0.269) exceeds 0.25.
  Chain 4: Left tail hat{xi} (0.333) exceeds 0.25.

kappas[44]:
  Chain 1: Right tail hat{xi} (0.276) exceeds 0.25.

kappas[48]:
  Chain 2: Left tail hat{xi} (0.270) exceeds 0.25.
  Chain 3: Left tail hat{xi} (0.292) exceeds 0.25.

kappas[94]:
  Chain 3: Right tail hat{xi} (0.284) exceeds 0.25.
  Chain 1: hat{ESS} (61.972) is smaller than desired (100).

kappas[98]:
  Chain 1: Both left and right tail hat{xi}s (0.260, 0.256) exceed 0.25.
  Chain 2: Left tail hat{xi} (0.337) exceeds 0.25.
  Chain 3: Both left and right tail hat{xi}s (0.373, 0.310) exceed 0.25.
  Chain 4: Both left and right tail hat{xi}s (0.327, 0.268) exceed 0.25.


Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.

Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
\end{verbatim}

Fortunately this looks to be exactly the case.

\begin{codelisting}

\caption{\texttt{model4b.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who forfeit and did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting forfeited entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}

  \CommentTok{// Forfeited entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs;}

  \CommentTok{// MapRando versioning}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_versions;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_versions\textgreater{} version\_idxs;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Non{-}centered relative seed difficulties}
  \DataTypeTok{vector}\NormalTok{[N\_races {-} }\DecValTok{1}\NormalTok{] rel\_difficulties\_free\_tilde;}

  \CommentTok{// Relative eed difficulty population configuration}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] mu\_rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] tau\_rel\_difficulties;}

  \CommentTok{// Non{-}centered relative entrant skills}
  \DataTypeTok{vector}\NormalTok{[N\_entrants {-} }\DecValTok{1}\NormalTok{] rel\_skills\_free;}

  \CommentTok{// Relative entrant skill population configuration}
  \DataTypeTok{real}\NormalTok{ mu\_rel\_skills;}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} tau\_rel\_skills;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \CommentTok{// Center the non{-}centered relative difficulties}
  \CommentTok{// and skills while inserting the anchors}
  \DataTypeTok{vector}\NormalTok{[N\_races] rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{[N\_entrants] rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_skills\_free[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    = rel\_skills\_free[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

\NormalTok{  rel\_difficulties\_free\_tilde \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  mu\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  rel\_skills\_free \textasciitilde{} normal(mu\_rel\_skills, tau\_rel\_skills);}
\NormalTok{  mu\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);   }\CommentTok{//  0 \textless{}\textasciitilde{} psi    \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{); }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);  }\CommentTok{//  0 \textless{}\textasciitilde{} betas  \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Posterior predictions}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times\_pred;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_N\_entrants\_dnf\_pred = rep\_array(}\DecValTok{0}\NormalTok{, N\_races);}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who forfeited}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}

    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

      \CommentTok{// Finish time prediction conditioned on not forfeiting}
\NormalTok{      race\_entrant\_f\_times\_pred[race\_f\_start\_idxs[r] + n {-} }\DecValTok{1}\NormalTok{]}
\NormalTok{        = inv\_gamma\_md\_rng(mu, psi);}

      \CommentTok{// Forfeit prediction}
\NormalTok{      race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \CommentTok{// Forfeit prediction}
\NormalTok{        race\_N\_entrants\_dnf\_pred[r] += bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model4b.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples4 }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\_tilde\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
kappas[31]:
  Chain 4: Left tail hat{xi} (0.325) exceeds 0.25.

kappas[44]:
  Chain 1: Right tail hat{xi} (0.271) exceeds 0.25.
  Chain 2: Right tail hat{xi} (0.253) exceeds 0.25.

kappas[94]:
  Chain 2: Right tail hat{xi} (0.374) exceeds 0.25.

kappas[98]:
  Chain 1: Both left and right tail hat{xi}s (0.354, 0.337) exceed 0.25.
  Chain 3: Left tail hat{xi} (0.373) exceeds 0.25.
  Chain 4: Left tail hat{xi} (0.295) exceeds 0.25.


Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.
\end{verbatim}

A review of our visual retrodictive checks doesn't show any indications
that the introduction of the hierarchical coupling compromised the
adequacy of our modeling assumptions.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(samples4, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                         \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times,}
                         \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                         \AttributeTok{main=}\StringTok{"All Races, All Entrants"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-57-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_N\_entrants\_dnf\_pred[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf,}
                                     \AttributeTok{residual=}\ConstantTok{TRUE}\NormalTok{,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"N\_dnf"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-58-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{77}\NormalTok{, }\DecValTok{140}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n)}
                  \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{11000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Race "}\NormalTok{, r, }\StringTok{", All Entrants"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 104 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 109 predictive values (0.2%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 7 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-59-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in} \FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{73}\NormalTok{, }\DecValTok{93}\NormalTok{)) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs }\SpecialCharTok{==}\NormalTok{ e)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(idxs,}
                  \ControlFlowTok{function}\NormalTok{(n)}
                  \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, n, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  filtered\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples4, names)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_hist\_quantiles}\NormalTok{(filtered\_samples, }\StringTok{\textquotesingle{}race\_entrant\_f\_times\_pred\textquotesingle{}}\NormalTok{,}
                           \DecValTok{1000}\NormalTok{, }\DecValTok{12000}\NormalTok{, }\DecValTok{1000}\NormalTok{,}
                           \AttributeTok{baseline\_values=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_times[idxs],}
                           \AttributeTok{xlab=}\StringTok{"Finish Time (s)"}\NormalTok{,}
                           \AttributeTok{main=}\FunctionTok{paste0}\NormalTok{(}\StringTok{"All Races, Entrant "}\NormalTok{, e))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 3 predictive values (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 1 predictive value (0.0%) fell above the binning.
\end{verbatim}

\begin{verbatim}
Warning in check_bin_containment(bin_min, bin_max, collapsed_values,
"predictive value"): 14 predictive values (0.0%) fell above the binning.
\end{verbatim}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-60-1.pdf}

Now we can explore the posterior inferences for not just the individual
behaviors but also the hierarchical populations from which those
behaviors are, at least mathematically, drawn.

Each MapRando version defines a separate hierarchical population and,
unsurprisingly, the inferred population behavior is most precise for the
later versions that have been played the most.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions) \{}
  \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{  races }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{version\_idxs }\SpecialCharTok{==}\NormalTok{ v)}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(races, }\ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{  names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(names, }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}mu\_rel\_difficulties[\textquotesingle{}}\NormalTok{, v, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}

\NormalTok{  version\_name }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\StringTok{"Version"}\NormalTok{, uniq\_versions[v])}

\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                       \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                       \AttributeTok{xticklabs=}\FunctionTok{c}\NormalTok{(races, }\StringTok{\textquotesingle{}mu\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{,}
                                       \AttributeTok{main=}\NormalTok{version\_name)}
  \FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\FunctionTok{length}\NormalTok{(races) }\SpecialCharTok{+} \FloatTok{0.5}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{)}

\NormalTok{  name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}tau\_rel\_difficulties[\textquotesingle{}}\NormalTok{, v, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{  display\_name }\OtherTok{\textless{}{-}} \StringTok{"Relative Difficulty Population Scale"}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{30}\NormalTok{, }\AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{1.1}\NormalTok{),}
                                  \AttributeTok{display\_name=}\NormalTok{display\_name,}
                                  \AttributeTok{main=}\NormalTok{version\_name)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-1.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-2.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-3.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-4.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-5.pdf}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-61-6.pdf}

Subject to the posterior uncertainties all of the version population
behaviors are consistent with each other. For example both versions 112
and 113 strongly suppress relative seed difficulty magnitudes above \[
2 \tau_{\mathrm{difficulty}} \approx 0.4,
\] implying range of proportional changes to the baseline finish time
between \[
\exp(-0.4) \approx 0.67
\] and \[
\exp(+0.4) \approx 1.49.
\]

Interestingly the entrant skills exhibit similar regularization, with
the population scale concentrating just under \(0.3\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                \ControlFlowTok{function}\NormalTok{(n) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, n,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(names, }\StringTok{\textquotesingle{}mu\_rel\_skills\textquotesingle{}}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Entrant"}\NormalTok{,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Skill"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \FloatTok{0.5}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\StringTok{"\#DDDDDD"}\NormalTok{)}

\NormalTok{display\_name }\OtherTok{\textless{}{-}} \StringTok{"Relative Skill Population Scale"}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[}\StringTok{\textquotesingle{}tau\_rel\_skills\textquotesingle{}}\NormalTok{]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{display\_name=}\NormalTok{display\_name)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-62-1.pdf}

\subsection{Inferential Comparison}\label{sec:inf-comp}

Before applying our posterior inferences to make useful statements about
the entrants and their behavior in future races let's pause and examine
the impact our model development has had on our posterior inferences.

\subsubsection{Log Baseline}\label{log-baseline}

To start let's look at the parameter \(\eta\) which, once exponentiated,
sets the baseline finish time.

Interestingly changing the observational model doesn't seem to have
strongly impacted the inferences for \(\eta\), at least within the
resolution of our Markov chain Monte Carlo estimators.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{18}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"eta"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{7.93}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.15}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-63-1.pdf}

On the other hand incorporating forfeits results in a slight shift of
the entire marginal posterior distribution towards larger values. This
direction makes sense because without accounting for forfeits the
observed finish times are biased towards more optimistic outcomes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{18}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"eta"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{7.95}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.17}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-64-1.pdf}

The introduction of the seed difficulty and entrant skill hierarchies
substantially shifts the posterior inferences for \(\eta\) down towards
smaller values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{15}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"eta"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{8.17}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{]], }\DecValTok{30}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\FloatTok{7.6}\NormalTok{, }\FloatTok{8.25}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{7.75}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-65-1.pdf}

\subsubsection{Entrant 65 Relative
Skill}\label{entrant-65-relative-skill}

Now let's dig into posterior inferences for some entrants with
particularly extreme observed behaviors that will hopefully emphasize
the impact of our model improvements.

For example the record of entrant 65 features lots of entrances and only
a single forfeit. Consequently we might naively expect the introduction
of forfeits and the entrant skill hierarchy to have less impact on
inferences for the skill parameter of entrant 65 relative to the anchor
entrant 29.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 65
  64 total entrances
  63 finishes (98.4%)
  1 forfeit (1.6%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Relative Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If anything transitioning from a gamma to inverse gamma observational
model yields a very slight shift of the marginal skill posterior
distribution to larger values. On the other hand because this shift is
largely enveloped by the Markov chain Monte Carlo errors it could also
just be a computational artifact.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.15}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-68-1.pdf}

The introduction of forfeits into the model has a slightly stronger
impact on the marginal skill posterior distribution, shifting it up to
further larger values. Even though entrant 65 rarely forfeited the
ignorance of forfeits can allow data from other entrants to bias
inferences for common parameters like \(\eta\), which then biases
inferences for all entrant skills.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.15}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-69-1.pdf}

The introduction of the skill hierarchy has an even stronger effect,
only this time in the opposite direction with the posterior inferences
regularized towards more negative values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.18}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-70-1.pdf}

\subsubsection{Entrant 44 Relative
Skill}\label{entrant-44-relative-skill}

Let's contrast these changes with those for the relative skill parameter
of entrant 44, who also entered into many races but forfeited at a much
higher rate than entrant 65.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{44}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 44
  71 total entrances
  56 finishes (78.9%)
  15 forfeits (21.1%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Relative Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Again the tweak of the observational model has a negligible impact on
the marginal posterior inferences.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.23}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-73-1.pdf}

Somewhat surprisingly incorporating forfeits shifts the entrant 44
relative skill parameter to larger values!

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.23}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-74-1.pdf}

This suggests that entrant 44 forfeited for only particularly difficult
races. Indeed examining the seed difficulty inferences it appears that
entrant 44 has largely forfeited only when confronted with more
difficult seeds.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_f\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_f\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_f\_idxs[idxs])}
\NormalTok{    f\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(f\_races, r)}
\NormalTok{\}}

\NormalTok{dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_races) \{}
  \ControlFlowTok{if}\NormalTok{ (data}\SpecialCharTok{$}\NormalTok{race\_N\_entrants\_dnf[r] }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\ControlFlowTok{next}
\NormalTok{  idxs }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_dnf\_start\_idxs[r]}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{race\_dnf\_end\_idxs[r]}
  \ControlFlowTok{if}\NormalTok{ (e }\SpecialCharTok{\%in\%}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{race\_entrant\_dnf\_idxs[idxs])}
\NormalTok{    dnf\_races }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(dnf\_races, r)}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(f\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{f\_races,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{,}
                                     \AttributeTok{display\_ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{1.0}\NormalTok{),}
                                     \AttributeTok{main=}\StringTok{"Entrant 44 Finished"}\NormalTok{)}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(dnf\_races,}
                \ControlFlowTok{function}\NormalTok{(r) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_disc\_pushforward\_quantiles}\NormalTok{(samples4, names,}
                                     \AttributeTok{xlab=}\StringTok{"Race"}\NormalTok{,}
                                     \AttributeTok{xticklabs=}\NormalTok{dnf\_races,}
                                     \AttributeTok{ylab=}\StringTok{"Relative Difficulty"}\NormalTok{,}
                                     \AttributeTok{display\_ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{1.0}\NormalTok{),}
                                     \AttributeTok{main=}\StringTok{"Entrant 44 Forfeited"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-75-1.pdf}

With the introduction of a skill hierarchy the posterior inferences for
the relative skill parameter of entrant 44 are regularized towards more
negative values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.35}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.28}\NormalTok{, }\DecValTok{10}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-76-1.pdf}

\subsubsection{Entrant 83 Relative
Skill}\label{entrant-83-relative-skill}

Lastly let's take a look at an entrant with only a few race entrances.
In particular entrant 83 has only five entrances and almost half of them
are forfeits.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{83}
\FunctionTok{summarize\_entrant}\NormalTok{(e)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Entrant 83
  5 total entrances
  3 finishes (60.0%)
  2 forfeits (40.0%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{xname }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}Entrant \textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{} Relative Skill\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once again the transition from gamma to inverse gamma observational
models has little impact on the marginal skill inferences.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples1[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.38}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 1"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.82}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-79-1.pdf}

Incorporating forfeits perhaps slightly pushes the skill marginal
posterior distribution to larger values, but the differences are largely
consistent with the Markov chain Monte Carlo estimator error.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples2[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.82}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 2"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.38}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-80-1.pdf}

The hierarchical coupling weakly shifts the posterior inferences towards
more negative skill values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples3[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{display\_name=}\NormalTok{xname,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.38}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 3"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{20}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{),}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.82}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"Model 4"}\NormalTok{, }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-81-1.pdf}

\subsection{Possible Model Expansions}\label{possible-model-expansions}

At this point our model appears to adequately capture the observed
summary statistics behaviors. That said because we spot checked the
retrodictive behavior for only a few individual races and entrants there
is plenty of room for subtle model inadequacies to hide. Moreover the
available domain expertise suggests plenty of possible model
improvements that we could investigate more carefully if we had the
time, need, or both.

Attempting to implement any of these model expansions would be a useful
exercise for any enterprising readers.

\subsubsection{Idiosyncratic Entrants}\label{idiosyncratic-entrants}

Given that we have already argued that our domain expertise about the
entrant behaviors is exchangeable there is nothing preventing us from
hierarchically modeling the variation in not only entrant skill but also
entrant forfeit behaviors.

If entrant skill, forfeit threshold, and forfeit scale all varied
independently then implementing this model would be mostly
straightforward, with some possible challenges in accommodating the
positivity constraint on the forfeit scale. There's no immediate reason,
however, why the heterogeneity in these parameters couldn't be coupled
together. For example entrants with higher skills might also tend to
have higher forfeit thresholds and vice versa. In this case we would
need to consider a multivariate hierarchical population model.

This is the inevitable challenge with hierarchical modeling in practice.
Once we identify which behaviors are heterogeneous and exchangeable we
still need to determine \emph{how} those behaviors could vary.

\subsubsection{Non-Normal Population
Models}\label{non-normal-population-models}

Speaking of hierarchies, we are in a somewhat privileged position with
the large number of entrants and seeds in our data set. This abundance
of contexts might allow us to resolve subtle hierarchical population
behaviors that would require non-normal population models. For example
we might need to consider population models that accommodate sparsity,
asymmetry, and more.

One way to motivate possible population model behaviors is to examine
the distribution of expected relative difficulties and expected relative
skills from our last non-hierarchical model. For example the expected
relative difficulties within each version appear to be consistent with a
normal population model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{expected\_difficulty }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(r)\{}
\NormalTok{  name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_difficulties[\textquotesingle{}}\NormalTok{, r, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples3[[name]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}

\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_versions) \{}
\NormalTok{  mean\_rel\_difficulties }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\FunctionTok{which}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{version\_idxs }\SpecialCharTok{==}\NormalTok{ v),}
\NormalTok{                                  expected\_difficulty)}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(mean\_rel\_difficulties, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.25}\NormalTok{,}
                      \AttributeTok{xlab=}\StringTok{"Expected Relative Skills"}\NormalTok{,}
                      \AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Version"}\NormalTok{, v))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-82-1.pdf}

On the other hand the expected relative skills appear to be much more
asymmetric than a normal population model can accommodate.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{expected\_skill }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples3[[}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}

\NormalTok{mean\_rel\_skills }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants, expected\_skill)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_line\_hist}\NormalTok{(mean\_rel\_skills, }\SpecialCharTok{{-}}\FloatTok{1.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.15}\NormalTok{,}
                    \AttributeTok{xlab=}\StringTok{"Expected Relative Skills"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-83-1.pdf}

In particular our use of a normal population model here might be
over-regularizing posterior inferences for the more skilled entrants. An
asymmetric population model for the relative skills, for instance a skew
normal population model, might yield more accurate inferences and
predictions.

\subsubsection{Self-Improvement}\label{self-improvement}

When exploring the time-dependence of the seed difficulties we briefly
considered time-dependent entrant skills before accepting the evolving
MapRando version as the most likely explanation. That said there's no
reason why we couldn't expand our model to allow for time-dependent
entrant skills, if only to see if we could resolve any substantial
dependencies with the data we have collected.

The main challenge with implementing time-dependent skills is
determining how exactly to model how entrants improve and hence what
kinds of time-dependencies we should prioritize. For example if
improvement scales with the number of MapRando games played, and entrant
interest in the game is not uniform in time, then modeling skill as a
function of race date-time might not be the most best path. Instead it
might be more productive to allow entrant skills to depend on cumulative
participation if not something else entirely.

We still then have to determine the possible functional relationships
between skill and the appropriate evolution metric. We could, for
instance, simply assume a linear relationship for simplicity or consider
more sophisticated relationships that allow for behaviors like
saturation.

\subsubsection{Variable Variability}\label{variable-variability}

Throughout our model development have assumed a common \(\psi\) across
all races, even as the randomization seeds change. That said sometimes
the MapRando randomization logic results in particularly ambiguous
progression paths; entrants taking the right path first will tend to
finish especially fast while those who explore the wrong paths will tend
to finish later, resulting in especially large variability regardless of
entrant skill. On the other hand some seeds result in progression paths
that are easier to predict, narrowing the range of possible finish
times.

One way to account for this heterogeneity is to allow \(\psi\) to vary
across race seeds. We could even model the \(\psi\) parameters
hierarchically to help regularize inferences for races with only a few
entrants.

Before expanding the model, however, we would first want to see if we
could identify any consequences of this behavior in new posterior
retrodictive checks. For example we might look at the finish time
histograms for more races to see if the observed behavior is wider or
narrow than the posterior predictive behavior. We could also try to
engineer summary statistics that are directly sensitive to the
variability, such as the ratio of the empirical variance to the squared
empirical mean within each race or statistics that are sensitive to
heterogeneity in those individual race statistics.

At the same time entrants who are more experienced with MapRando games,
especially the underlying logic of the map randomization, can often
identify the correct progression paths quickly and avoid wasting time
exploring dead ends. This suggests that \(\psi\) could also vary across
entrants. The study of this heterogeneity would proceed similarly to the
above study of seed heterogeneity, only separating the summary
statistics by individual entrants instead of individual races.

\section{Actionable Insights}\label{actionable-insights}

Although it's easy to become distracted by all of the directions we can
take our final model we shouldn't dismiss all of the powerful things
that we can already do with it. In this section we'll apply our
posterior inferences to a few applications that might arise in actual
practice.

\subsection{Ranking Entrants}\label{ranking-entrants}

A common objective of races is to construct leader boards where entrants
are ranked in order of their performance. For example
\texttt{https://racetime.gg/smr} uses a heuristic, iterative system to
assign points to entrants based on their placement in each race and then
uses those points to determine a dynamic
\href{https://racetime.gg/smr/leaderboards}{leader board}. The top nine
entrants as of August 3rd, 2024 are shown in
Table~\ref{tbl-leader-board}.

\begin{longtable}[]{@{}llllllllll@{}}
\caption{The website \texttt{https://racetime.gg/smr} ranks entrants
based on points earned during each
race.}\label{tbl-leader-board}\tabularnewline
\toprule\noalign{}
Rank & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Rank & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Entrant Index & 70 & 105 & 29 & 100 & 18 & 91 & 60 & 65 & 4 \\
\end{longtable}

As discussed in
\href{https://betanalpha.github.io/assets/chapters_html/pairwise_comparison_modeling.html\#ranking-items}{Section
5} of the pairwise comparison modeling chapter we can rank the entrants
by their inferred skills.

For instance we can always rank the entrants by the posterior
expectation values of their individual relative skills.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expected\_skill }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(e) \{}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples4[[}\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}

\NormalTok{expected\_skills }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants,}
                          \ControlFlowTok{function}\NormalTok{(e) }\FunctionTok{expected\_skill}\NormalTok{(e))}

\NormalTok{ranked\_entrants }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(expected\_skills, }\AttributeTok{index.return=}\ConstantTok{TRUE}\NormalTok{)}\SpecialCharTok{$}\NormalTok{ix}

\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{) \{}
  \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Rank \%i: Entrant \%i}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
\NormalTok{              r, ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ r]))}
  \ControlFlowTok{if}\NormalTok{ (r }\SpecialCharTok{==} \DecValTok{9}\NormalTok{) }\FunctionTok{cat}\NormalTok{(}\StringTok{"..."}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rank 1: Entrant 70
Rank 2: Entrant 29
Rank 3: Entrant 18
Rank 4: Entrant 105
Rank 5: Entrant 100
Rank 6: Entrant 91
Rank 7: Entrant 60
Rank 8: Entrant 65
Rank 9: Entrant 24
...
\end{verbatim}

This heuristic ranking is similar to the official
\texttt{https://racetime.gg/smr} leader boards, but not quite the same.
In both cases the first eight ranks are held by the same eight entrants,
although the position of the ranks is slightly permuted.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rank }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{9}
\NormalTok{post\_mean\_ranking }\OtherTok{\textless{}{-}} \FunctionTok{rev}\NormalTok{(}\FunctionTok{tail}\NormalTok{(ranked\_entrants, }\DecValTok{9}\NormalTok{))}
\NormalTok{racetime\_ranking }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{70}\NormalTok{, }\DecValTok{105}\NormalTok{, }\DecValTok{29}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{91}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{4}\NormalTok{)}

\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(rank, post\_mean\_ranking, racetime\_ranking)}
\FunctionTok{names}\NormalTok{(df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Rank"}\NormalTok{, }\StringTok{"Posterior Mean Ranking"}\NormalTok{, }\StringTok{"racetime.gg Ranking"}\NormalTok{)}

\FunctionTok{print}\NormalTok{(df, }\AttributeTok{row.names=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 Rank Posterior Mean Ranking racetime.gg Ranking
    1                     70                  70
    2                     29                 105
    3                     18                  29
    4                    105                 100
    5                    100                  18
    6                     91                  91
    7                     60                  60
    8                     65                  65
    9                     24                   4
\end{verbatim}

Inconsistent rankings are not at all surprising given the subtle
differences in their construction; the expected rankings are based on
race finish times while the \texttt{https://racetime.gg/smr} rankings
are based on race placement. Moreover the uncertainty in our inferences
allow for multiple rankings to be consistent with the observed data.

For example even though entrant 70 exhibits a higher expected skill than
entrant 29 our inferential uncertainties are not inconsistent with the
exact skill of entrant 29 actually surpassing the exact skill of entrant
70. Recall that entrant 29 is the anchor so their relative skill is
exactly zero.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{3}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Relative Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{, }\FloatTok{11.5}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 3}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\DecValTok{25}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 2}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_mid)}

\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples4[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.15}\NormalTok{, }\FloatTok{11.5}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Rank 1}\SpecialCharTok{\textbackslash{}n}\StringTok{Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-86-1.pdf}

If we want to compare only two entrants at a time then instead of
comparing their expected skills we can compute the posterior probability
that one skill surpasses the other. Unlike differences in expected
skills this latter comparison accounts for any inferential coupling
between the two skill parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e1 }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{]}
\NormalTok{e2 }\OtherTok{\textless{}{-}}\NormalTok{ ranked\_entrants[data}\SpecialCharTok{$}\NormalTok{N\_entrants }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{]}
\NormalTok{var\_repl }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}s1\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e1,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{),}
                 \StringTok{\textquotesingle{}s2\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e2,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))}

\NormalTok{p\_est }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{implicit\_subset\_prob}\NormalTok{(samples4,}
                            \ControlFlowTok{function}\NormalTok{(s1, s2) s1 }\SpecialCharTok{\textgreater{}}\NormalTok{ s2,}
\NormalTok{                            var\_repl)}

\NormalTok{format\_string }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"Posterior probability that entrant \%i skill "}\NormalTok{,}
                        \StringTok{"\textgreater{} entrant \%i skill = \%.3f +/{-} \%.3f."}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(format\_string, e1, e2, p\_est[}\DecValTok{1}\NormalTok{], }\DecValTok{2} \SpecialCharTok{*}\NormalTok{ p\_est[}\DecValTok{2}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Posterior probability that entrant 70 skill > entrant 29 skill = 0.982 +/- 0.005.
\end{verbatim}

These relative comparisons can also be used to construct another
heuristic ranking. For example we could compute the probability that the
skill of each entrant is larger than all other entrants and assign first
place based on the highest probability. Then we could compute the
probability that the skill of each remaining entrant is larger than all
of the other remaining entrants and assign second place based on the
highest of these probabilities. Finally we could fill out all of the
rankings by iterating this procedure until only one entrant is left to
occupy last place.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{skill\_comp }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(active\_skill, other\_skills) \{}
\NormalTok{  pairwise\_comps }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(other\_skills,}
                           \ControlFlowTok{function}\NormalTok{(other\_skill)}
\NormalTok{                           active\_skill }\SpecialCharTok{\textgreater{}}\NormalTok{ other\_skill)}
  \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{Reduce}\NormalTok{(}\StringTok{"\&"}\NormalTok{, pairwise\_comps))}
\NormalTok{\}}

\NormalTok{best\_entrant }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(entrant\_idxs) \{}
\NormalTok{  probs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{()}

  \ControlFlowTok{for}\NormalTok{ (e }\ControlFlowTok{in}\NormalTok{ entrant\_idxs) \{}
\NormalTok{    other\_entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e)]}
\NormalTok{    var\_repl }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}active\_skill\textquotesingle{}} \OtherTok{=} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{),}
                     \StringTok{\textquotesingle{}other\_skills\textquotesingle{}} \OtherTok{=} \FunctionTok{array}\NormalTok{(}\FunctionTok{sapply}\NormalTok{(other\_entrant\_idxs,}
                                                   \ControlFlowTok{function}\NormalTok{(oe)}
                                                   \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, oe,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{))))}

\NormalTok{    prob\_est }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{implicit\_subset\_prob}\NormalTok{(samples4,}
\NormalTok{                                          skill\_comp,}
\NormalTok{                                          var\_repl)}
\NormalTok{    probs }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(probs, prob\_est[}\DecValTok{1}\NormalTok{])}
\NormalTok{  \}}

\NormalTok{  entrant\_idxs[}\FunctionTok{which}\NormalTok{(probs }\SpecialCharTok{==} \FunctionTok{max}\NormalTok{(probs))]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{N\_entrants}
\NormalTok{e\_first }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"First Place: Entrant \%i"}\NormalTok{, e\_first))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
First Place: Entrant 70
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e\_first)]}
\NormalTok{e\_second }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Second Place: Entrant \%i"}\NormalTok{, e\_second))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Second Place: Entrant 29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{entrant\_idxs }\OtherTok{\textless{}{-}}\NormalTok{ entrant\_idxs[}\SpecialCharTok{{-}}\FunctionTok{which}\NormalTok{(entrant\_idxs }\SpecialCharTok{==}\NormalTok{ e\_second)]}
\NormalTok{e\_third }\OtherTok{\textless{}{-}} \FunctionTok{best\_entrant}\NormalTok{(entrant\_idxs)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Third Place: Entrant \%i"}\NormalTok{, e\_third))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Third Place: Entrant 18
\end{verbatim}

Interestingly this gives the same top three as the ranking of entrants
by their posterior expected skills, which is not generally the case.
This suggests that the differences between the expected skill rankings
and the \texttt{https://racetime.gg/smr} rankings may have more to do
with the difference between comparing finish times to finish placements.

The practical limitation of this second ranking approach is that it
requires estimating \emph{a lot} of expectation values. Moreover if we
really wanted to be careful then we would need to ensure that the Markov
chain Monte Carlo error for each probability estimate is smaller than
any of the differences between the probability estimates so that the
resulting ranks are not corrupted by computational artifacts. In
practice this might require running more Markov chains than usual,
longer Markov chains than usual, or both.

\subsection{Predicting Race Outcomes}\label{predicting-race-outcomes}

Another common application is to make predictions about the outcomes of
future races, or even hypothetical races that might never occur. We can
use our posterior inferences for the observed seed and entrants to
immediately inform predictions about how existing entrants would fare if
they were able to play previous seeds again. In order to make
predictions about the performance of entirely new entrants or new seeds
we will need to take advantage of the hierarchical population models.

Let's rerun our last, hierarchical model only with a new
\texttt{generated\ quantities} block where we simulate posterior
predictive finish statuses and finish times for all entrants in a
hypothetical race using a new seed in the latest MapRando version.

\begin{codelisting}

\caption{\texttt{model5.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{functions}\NormalTok{ \{}
  \CommentTok{// Mean{-}dispersion parameterization of inverse gamma family}
  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_lpdf(}\DataTypeTok{real}\NormalTok{ x, }\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_lpdf(x | inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}

  \DataTypeTok{real}\NormalTok{ inv\_gamma\_md\_rng(}\DataTypeTok{real}\NormalTok{ mu, }\DataTypeTok{real}\NormalTok{ psi) \{}
    \ControlFlowTok{return}\NormalTok{ inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{, mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_races;    }\CommentTok{// Total number of races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrants; }\CommentTok{// Total number of entrants}
  \CommentTok{// Each entrant is assigned a unique index in [1, N\_entrants]}

  \CommentTok{// Number of entrants in each race who finished}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_f;}

  \CommentTok{// Indices for extracting finished entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_f\_end\_idxs;}

  \CommentTok{// Number of entrants in each race who forfeit and did not finish}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} race\_N\_entrants\_dnf;}

  \CommentTok{// Indices for extracting forfeited entrant information in each race}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_start\_idxs;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{ race\_dnf\_end\_idxs;}

  \CommentTok{// Total number of finishes across all races}
  \DataTypeTok{int}\NormalTok{ \textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_entrances\_fs;}

  \CommentTok{// Finished entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_f\_idxs;}

  \CommentTok{// Entrant finish times within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_fs] }\DataTypeTok{real}\NormalTok{ race\_entrant\_f\_times;}

  \CommentTok{// Total number of forfeits across all races}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N\_entrances\_dnfs;}

  \CommentTok{// Forfeited entrant indices within each race}
  \DataTypeTok{array}\NormalTok{[N\_entrances\_dnfs] }\DataTypeTok{int}\NormalTok{ race\_entrant\_dnf\_idxs;}

  \CommentTok{// MapRando versioning}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} N\_versions;}
  \DataTypeTok{array}\NormalTok{[N\_races] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_versions\textgreater{} version\_idxs;}

  \CommentTok{// Anchor configuration}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_races\textgreater{} anchor\_race\_idx;}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{1}\NormalTok{, }\KeywordTok{upper}\NormalTok{=N\_entrants\textgreater{} anchor\_entrant\_idx;}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ eta; }\CommentTok{// Log baseline finish time (log seconds)}

  \CommentTok{// Non{-}centered relative seed difficulties}
  \DataTypeTok{vector}\NormalTok{[N\_races {-} }\DecValTok{1}\NormalTok{] rel\_difficulties\_free\_tilde;}

  \CommentTok{// Relative eed difficulty population configuration}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] mu\_rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{}[N\_versions] tau\_rel\_difficulties;}

  \CommentTok{// Non{-}centered relative entrant skills}
  \DataTypeTok{vector}\NormalTok{[N\_entrants {-} }\DecValTok{1}\NormalTok{] rel\_skills\_free;}

  \CommentTok{// Relative entrant skill population configuration}
  \DataTypeTok{real}\NormalTok{ mu\_rel\_skills;}
  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} tau\_rel\_skills;}

  \DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} psi; }\CommentTok{// Inverse gamma dispersion configuration}

  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ kappas;         }\CommentTok{// Forfeit thresholds}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} betas; }\CommentTok{// Forfeit scalings}
\NormalTok{\}}

\KeywordTok{transformed parameters}\NormalTok{ \{}
  \CommentTok{// Center the non{-}centered relative difficulties}
  \CommentTok{// and skills while inserting the anchors}
  \DataTypeTok{vector}\NormalTok{[N\_races] rel\_difficulties;}
  \DataTypeTok{vector}\NormalTok{[N\_entrants] rel\_skills;}

\NormalTok{  rel\_difficulties[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[}\DecValTok{1}\NormalTok{:(anchor\_race\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_difficulties[anchor\_race\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_difficulties[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]}
\NormalTok{    =   mu\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{      +    tau\_rel\_difficulties[version\_idxs[(anchor\_race\_idx + }\DecValTok{1}\NormalTok{):N\_races]]}
\NormalTok{        .* rel\_difficulties\_free\_tilde[anchor\_race\_idx:(N\_races {-} }\DecValTok{1}\NormalTok{)];}

\NormalTok{  rel\_skills[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)]}
\NormalTok{    =  rel\_skills\_free[}\DecValTok{1}\NormalTok{:(anchor\_entrant\_idx {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{  rel\_skills[anchor\_entrant\_idx] = }\DecValTok{0}\NormalTok{;}
\NormalTok{  rel\_skills[(anchor\_entrant\_idx + }\DecValTok{1}\NormalTok{):N\_entrants]}
\NormalTok{    = rel\_skills\_free[anchor\_entrant\_idx:(N\_entrants {-} }\DecValTok{1}\NormalTok{)];}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}

  \CommentTok{// log(1800 s) \textless{} eta \textless{} log(5400 s)}
\NormalTok{  eta \textasciitilde{} normal(}\FloatTok{8.045}\NormalTok{, }\FloatTok{0.237}\NormalTok{);}

\NormalTok{  rel\_difficulties\_free\_tilde \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  mu\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_difficulties \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  rel\_skills\_free \textasciitilde{} normal(mu\_rel\_skills, tau\_rel\_skills);}
\NormalTok{  mu\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.423}\NormalTok{);}
\NormalTok{  tau\_rel\_skills \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.381}\NormalTok{);}

\NormalTok{  psi \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.389}\NormalTok{);   }\CommentTok{//  0 \textless{}\textasciitilde{} psi    \textless{}\textasciitilde{} 1}
\NormalTok{  kappas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{2.16}\NormalTok{); }\CommentTok{// {-}5 \textless{}\textasciitilde{} kappas \textless{}\textasciitilde{} +5}
\NormalTok{  betas \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\FloatTok{1.95}\NormalTok{);  }\CommentTok{//  0 \textless{}\textasciitilde{} betas  \textless{}\textasciitilde{} +5}

  \CommentTok{// Observational model}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_races) \{}
    \CommentTok{// Extract details for entrants who finished}
    \DataTypeTok{int}\NormalTok{ N\_entrants\_f = race\_N\_entrants\_f[r];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ f\_idxs}
\NormalTok{      = linspaced\_int\_array(N\_entrants\_f,}
\NormalTok{                            race\_f\_start\_idxs[r],}
\NormalTok{                            race\_f\_end\_idxs[r]);}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{int}\NormalTok{ entrant\_f\_idxs}
\NormalTok{      = race\_entrant\_f\_idxs[f\_idxs];}
    \DataTypeTok{array}\NormalTok{[N\_entrants\_f] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times}
\NormalTok{      = race\_entrant\_f\_times[f\_idxs];}

    \CommentTok{// Finished entrant model}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_f) \{}
      \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_f\_idxs[n];}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

\NormalTok{      entrant\_f\_times[n] \textasciitilde{} inv\_gamma\_md(mu, psi);}
      \DecValTok{0}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did not forfeit}
\NormalTok{    \}}

    \ControlFlowTok{if}\NormalTok{ (race\_N\_entrants\_dnf[r] \textgreater{} }\DecValTok{0}\NormalTok{) \{}
      \CommentTok{// Extract details for entrants who forfeited}
      \DataTypeTok{int}\NormalTok{ N\_entrants\_dnf = race\_N\_entrants\_dnf[r];}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ dnf\_idxs = linspaced\_int\_array(N\_entrants\_dnf,}
\NormalTok{                                           race\_dnf\_start\_idxs[r],}
\NormalTok{                                           race\_dnf\_end\_idxs[r]);}
      \DataTypeTok{array}\NormalTok{[N\_entrants\_dnf]}
        \DataTypeTok{int}\NormalTok{ entrant\_dnf\_idxs = race\_entrant\_dnf\_idxs[dnf\_idxs];}

      \CommentTok{// Forfeited entrant model}
      \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants\_dnf) \{}
        \DataTypeTok{int}\NormalTok{ entrant\_idx = entrant\_dnf\_idxs[n];}
        \DataTypeTok{real}\NormalTok{ delta = rel\_difficulties[r] {-} rel\_skills[entrant\_idx];}
        \DataTypeTok{real}\NormalTok{ logit\_q = betas[entrant\_idx] * (delta {-} kappas[entrant\_idx]);}

        \DecValTok{1}\NormalTok{ \textasciitilde{} bernoulli\_logit(logit\_q); }\CommentTok{// Did forfeit}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \CommentTok{// Finish status in a hypothetical new race (0: finish, 1: forfeit)}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} entrant\_statuses\_pred;}

  \CommentTok{// Finish times in a hypothetical new race conditioned on no forfeits}
  \DataTypeTok{array}\NormalTok{[N\_entrants] }\DataTypeTok{real}\NormalTok{ entrant\_f\_times\_pred;}
\NormalTok{  \{}
    \CommentTok{// Simulate seed difficulty from latest version}
    \DataTypeTok{real}\NormalTok{ rel\_difficulty}
\NormalTok{      = normal\_rng(mu\_rel\_difficulties[N\_versions],}
\NormalTok{                   tau\_rel\_difficulties[N\_versions]);}
    \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N\_entrants) \{}
      \DataTypeTok{real}\NormalTok{ delta = rel\_difficulty {-} rel\_skills[n];}
      \DataTypeTok{real}\NormalTok{ mu = exp(eta + delta);}
      \DataTypeTok{real}\NormalTok{ logit\_q = betas[n] * (delta {-} kappas[n]);}

\NormalTok{      entrant\_statuses\_pred[n] = bernoulli\_logit\_rng(logit\_q);}
\NormalTok{      entrant\_f\_times\_pred[n] = inv\_gamma\_rng(inv(psi) + }\DecValTok{2}\NormalTok{,}
\NormalTok{                                              mu * (inv(psi) + }\DecValTok{1}\NormalTok{));}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/model5.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438339}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Because the \texttt{generated\ quantities} block of Model 5 will consume
pseudo-random number generate state differently than that of Model 4
there is a chance that the realized Markov chains will encounter
different pathologies. Consequently we'll need to double check the
computational diagnostics. Fortunately no new warnings have arisen.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  All Hamiltonian Monte Carlo diagnostics are consistent with reliable
Markov chain Monte Carlo.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectand\_vals}\NormalTok{(fit)}
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples,}
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}eta\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_difficulties\_free\_tilde\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_difficulties\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}rel\_skills\_free\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}mu\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}tau\_rel\_skills\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}psi\textquotesingle{}}\NormalTok{,}
                                         \StringTok{\textquotesingle{}kappas\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}betas\textquotesingle{}}\NormalTok{),}
                                       \AttributeTok{check\_arrays=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
kappas[44]:
  Chain 1: Right tail hat{xi} (0.265) exceeds 0.25.
  Chain 2: Right tail hat{xi} (0.289) exceeds 0.25.
  Chain 4: Right tail hat{xi} (0.324) exceeds 0.25.

kappas[48]:
  Chain 4: Left tail hat{xi} (0.314) exceeds 0.25.

kappas[94]:
  Chain 1: Right tail hat{xi} (0.310) exceeds 0.25.

kappas[98]:
  Chain 1: Both left and right tail hat{xi}s (0.303, 0.319) exceed 0.25.
  Chain 2: Left tail hat{xi} (0.296) exceeds 0.25.
  Chain 3: Left tail hat{xi} (0.371) exceeds 0.25.
  Chain 4: Left tail hat{xi} (0.465) exceeds 0.25.


Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.
\end{verbatim}

The uses of these predictions are endless.

\subsubsection{Single Entrant
Predictions}\label{single-entrant-predictions}

For example some entrants not only live-stream their race entrances to
their communities but also allow viewers to make non-monetary,
over/under bets on their finish times. If we wanted to take these casual
activities a bit too far then we could use our predictions to set a
betting line where both outcomes are equally probable.

Without forfeits the balanced betting line \(t_{\mathrm{gamble}}\) would
be implicitly defined by the posterior predictive probability \[
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, ) = 0.5.
\] In other words \(t_{\mathrm{gamble}}\) would be given by the median
of the posterior predictive finish time distribution for the hosting
entrant, which we can estimate with Markov chain Monte Carlo.

To be accurate, however, we need to account for the fact that the
hosting entrant might forfeit. Consequently the relevant condition is
actually \begin{align*}
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, , \mathrm{forfeit} = 0 )
&=
0.5
\\
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 ) \,
\pi( \mathrm{forfeit} = 0 )
&=
0.5
\\
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 ) \,
\left( 1 - \pi( \mathrm{forfeit} = 1 ) \right)
&=
0.5,
\end{align*} or \[
\pi( \, [ 0, t_{\mathrm{gamble}} ) \, \mid \mathrm{forfeit} = 0 )
=
\frac{0.5}{ 1 - \pi( \mathrm{forfeit} = 1 ) }.
\]

Fortunately we can readily compute all of these ingredients using our
\texttt{Stan} output.

To demonstrate let's look at entrant 65. First we can compute the
probability of forfeit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_statuses\_pred[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{p\_dnf }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_est}\NormalTok{(samples[[name]])[}\DecValTok{1}\NormalTok{]}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Probability entrant \%i forfeits = \%.3f."}\NormalTok{, e, p\_dnf))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Probability entrant 65 forfeits = 0.017.
\end{verbatim}

Because the forfeit probability \texttt{p\_dnf} is so small the balanced
probability allocation needed to define \(t_{\mathrm{gamble}}\) is very
close to \(\frac{1}{2}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p\_balanced }\OtherTok{\textless{}{-}} \FloatTok{0.5} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_dnf)}
\end{Highlighting}
\end{Shaded}

Averaging the empirical quantiles within each Markov chain provides a
consistent estimate of the exact posterior quantile.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}
\NormalTok{t\_gamble }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{ensemble\_mcmc\_quantile\_est}\NormalTok{(samples[[name]],}
                                            \FunctionTok{c}\NormalTok{(p\_balanced))}

\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"t\_gamble = \%.3f minutes"}\NormalTok{, t\_gamble }\SpecialCharTok{/} \DecValTok{60}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
t_gamble = 64.146 minutes
\end{verbatim}

\subsubsection{Head-to-Head Predictions}\label{head-to-head-predictions}

We can also predict how two entrants will perform relative to each other
in our hypothetical race. Here we'll consider entrant 29 racing against
entrant 65.

The marginal posterior distribution for the two entrants' relative skill
parameters overlap quite a bit, but the relative skill of entrant 29
does favor larger values than that of entrant 65.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.02}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Relative Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\FloatTok{0.}\SpecialCharTok{{-}}\FloatTok{0.03}\NormalTok{, }\DecValTok{50}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}rel\_skills[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]], }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.02}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.18}\NormalTok{, }\DecValTok{10}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-97-1.pdf}

What really matters for predictive race outcomes, however, are not the
latent skills but rather the predicted finish times. The marginal
posterior predictive distributions for the predicted finish times
overlap even more, indicating a much closer race than we might expect
from the skills alone.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]] }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{175}\NormalTok{),}
                                \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.03}\NormalTok{),}
                                \AttributeTok{display\_name=}\StringTok{"Skill"}\NormalTok{,}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}
\FunctionTok{text}\NormalTok{(}\DecValTok{25}\NormalTok{, }\FloatTok{0.02}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_light)}

\NormalTok{e }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{name }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}entrant\_f\_times\_pred[\textquotesingle{}}\NormalTok{, e,}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)}

\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[name]] }\SpecialCharTok{/} \DecValTok{60}\NormalTok{, }\DecValTok{25}\NormalTok{,}
                                \AttributeTok{flim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{175}\NormalTok{),}
                                \AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark,}
                                \AttributeTok{border=}\StringTok{"\#BBBBBB88"}\NormalTok{,}
                                \AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{text}\NormalTok{(}\DecValTok{95}\NormalTok{, }\FloatTok{0.02}\NormalTok{, }\FunctionTok{paste}\NormalTok{(}\StringTok{"Entrant"}\NormalTok{, e), }\AttributeTok{col=}\NormalTok{util}\SpecialCharTok{$}\NormalTok{c\_dark)}
\end{Highlighting}
\end{Shaded}

\includegraphics{racing_files/figure-pdf/unnamed-chunk-98-1.pdf}

That said the predicted finish times still don't tell the entire story.
To accurately predict a winner we also need to take into account the
possibility that one, or possibly even both, of the entrants forfeits.
Altogether there are five possible outcomes that are relevant to whether
or not entrant 29 beats entrant 65:

\begin{itemize}
\tightlist
\item
  Entrant 29 forfeits and entrant 65 forfeits,
\item
  Entrant 29 forfeits and entrant 65 finishes,
\item
  Entrant 29 finishes and entrant 65 forfeits,
\item
  Entrant 29 finishes and entrant finishes and \(t_{29} < t_{65}\),
\item
  Entrant 29 finishes and entrant finishes and \(t_{29} > t_{65}\).
\end{itemize}

Of these entrant 29 decisively wins only in the third and fourth
outcomes.

In order to evaluate the probability that entrant 29 wins we'll need to
make careful use of conditional probability theory to account for all of
these outcomes, \begin{align*}
\pi( &\text{Entrant 29 beats entrant 65 } )
\\
&=\quad\;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1)
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0, t_{29} < t_{65})
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                      t_{29} < t_{65})
\\
&\quad+ \;\,
\pi( \text{Entrant 29 beats entrant 65 } \mid
     \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0, t_{29} > t_{65})
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} > t_{65})
\\
&=\quad\;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 1, \mathrm{forfeit}_{65} = 0 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 1
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 1
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} < t_{65})
\\
&\quad+ \;\,
\vphantom{\pi( \text{Entrant 29 beats entrant 65 } \mid} 0
\\
&\quad\quad \cdot \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
                       t_{29} > t_{65}),
\end{align*} or \begin{align*}
\pi( &\text{Entrant 29 beats entrant 65 } )
\\
&=\quad \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad + \pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0,
              t_{29} < t_{65})
\\
&=\quad \;\,
\pi( \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 1 )
\\
&\quad\ + \; \pi( t_{29} < t_{65} \mid
                  \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0 )
\\
&\quad\quad \cdot \pi(\mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0)
\\
&=\quad \;\,
p_{\text{forfeit win}}
\\
&\quad\ + \; \pi( t_{29} < t_{65} \mid
                  \mathrm{forfeit}_{29} = 0, \mathrm{forfeit}_{65} = 0 )
\cdot p_{\text{no forfeits}}.
\end{align*}

At that is left is using Markov chain Monte Carlo to estimate the three
posterior predictive probabilities on the right-hand side and then
combine them together to give the left-hand side.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e1 }\OtherTok{\textless{}{-}} \DecValTok{29}
\NormalTok{status\_name1 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_statuses\_pred["}\NormalTok{, e1, }\StringTok{"]"}\NormalTok{)}
\NormalTok{time\_name1 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_f\_times\_pred["}\NormalTok{, e1, }\StringTok{"]"}\NormalTok{)}

\NormalTok{e2 }\OtherTok{\textless{}{-}} \DecValTok{65}
\NormalTok{status\_name2 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_statuses\_pred["}\NormalTok{, e2, }\StringTok{"]"}\NormalTok{)}
\NormalTok{time\_name2 }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"entrant\_f\_times\_pred["}\NormalTok{, e2, }\StringTok{"]"}\NormalTok{)}

\NormalTok{p\_forfeit\_win\_est }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{implicit\_subset\_prob}\NormalTok{(samples,}
                            \ControlFlowTok{function}\NormalTok{(s1, s2) s1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ s2 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
                            \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}s1\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name1,}
                                 \StringTok{\textquotesingle{}s2\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name2))}

\NormalTok{p\_no\_forfeits\_est }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{implicit\_subset\_prob}\NormalTok{(samples,}
                            \ControlFlowTok{function}\NormalTok{(s1, s2) s1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ s2 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{,}
                            \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}s1\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name1,}
                                 \StringTok{\textquotesingle{}s2\textquotesingle{}} \OtherTok{=}\NormalTok{ status\_name2))}

\NormalTok{p\_neg\_time\_diff\_est }\OtherTok{\textless{}{-}}
\NormalTok{  util}\SpecialCharTok{$}\FunctionTok{implicit\_subset\_prob}\NormalTok{(samples,}
                            \ControlFlowTok{function}\NormalTok{(t1, t2) t1 }\SpecialCharTok{\textless{}}\NormalTok{ t2,}
                            \FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}t1\textquotesingle{}} \OtherTok{=}\NormalTok{ time\_name1,}
                                 \StringTok{\textquotesingle{}t2\textquotesingle{}} \OtherTok{=}\NormalTok{ time\_name2))}


\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ p\_forfeit\_win\_est[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ p\_neg\_time\_diff\_est[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ p\_no\_forfeits\_est[}\DecValTok{1}\NormalTok{]}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Probability that entrant \%i beats entrant \%i = \%.3f."}\NormalTok{,}
\NormalTok{            e1, e2, p))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Probability that entrant 29 beats entrant 65 = 0.704.
\end{verbatim}

Although entrant 29 is definitely favored the outcome is by no means
certain!

\section{Conclusion}\label{conclusion}

Although the domain of this analysis might be a bit niche the best
practices that it demonstrates are fundamental. By understanding the
provenance of the data we can motivate an initial probabilistic model
and then iteratively improve it until we can no longer resolve any model
inadequacies. The inferences from the final model not only provide a
variety of insights about the source of the data but also allow inform
all kinds of predictions that might be of practical relevance.

Being able to wax nostalgic about the glory days of the Super Nintendo
Entertainment System® and along the way celebrate open source projects
and the communities they inspire is just a pleasant bonus.

\section*{Acknowledgements}\label{acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}

I thank jd for helpful comments.

A very special thanks to everyone supporting me on Patreon: Adam
Fleischhacker, Adriano Yoshino, Alejandro Navarro-Martínez, Alessandro
Varacca, Alex D, Alexander Noll, Alexander Rosteck, Andrea Serafino,
Andrew Mascioli, Andrew Rouillard, Andrew Vigotsky, Ara Winter, Austin
Rochford, Avraham Adler, Ben Matthews, Ben Swallow, Benoit Essiambre,
Bertrand Wilden, Bradley Kolb, Brandon Liu, Brendan Galdo, Brynjolfur
Gauti Jónsson, Cameron Smith, Canaan Breiss, Cat Shark, CG, Charles
Naylor, Chase Dwelle, Chris Jones, Christopher Mehrvarzi, Colin Carroll,
Colin McAuliffe, Damien Mannion, dan mackinlay, Dan W Joyce, Dan Waxman,
Dan Weitzenfeld, Daniel Edward Marthaler, Daniel Saunders, Darshan
Pandit, Darthmaluus , David Galley, David Wurtz, Doug Rivers, Dr.~Jobo,
Dr.~Omri Har Shemesh, Dylan Maher, Ed Cashin, Edgar Merkle, Eric
LaMotte, Ero Carrera, Eugene O'Friel, Felipe González, Fergus Chadwick,
Finn Lindgren, Florian Wellmann, Geoff Rollins, Håkan Johansson, Hamed
Bastan-Hagh, Hauke Burde, Hector Munoz, Henri Wallen, hs, Hugo Botha,
Ian, Ian Costley, idontgetoutmuch, Ignacio Vera, Ilaria Prosdocimi,
Isaac Vock, Isidor Belic, J, J Michael Burgess, jacob pine, Jair
Andrade, James C, James Hodgson, James Wade, Janek Berger, Jason Martin,
Jason Pekos, Jason Wong, jd, Jeff Burnett, Jeff Dotson, Jeff Helzner,
Jeffrey Erlich, Jessica Graves, Joe Sloan, Joe Wagner, John Flournoy,
Jonathan H. Morgan, Jonathon Vallejo, Joran Jongerling, JU, June, Justin
Bois, Kádár András, Karim Naguib, Karim Osman, Kejia Shi, Kristian
Gårdhus Wichmann, Lars Barquist, lizzie , Logan Sullivan, LOU ODETTE,
Luís F, Marcel Lüthi, Marek Kwiatkowski, Mark Donoghoe, Markus P.,
Márton Vaitkus, Matt Moores, Matthew, Matthew Kay, Matthieu LEROY,
Mattia Arsendi, Maurits van der Meer, Michael Colaresi, Michael DeWitt,
Michael Dillon, Michael Lerner, Mick Cooney, Mike Lawrence, N Sanders,
N.S. , Name, Nathaniel Burbank, Nic Fishman, Nicholas Clark, Nicholas
Cowie, Nick S, Octavio Medina, Ole Rogeberg, Oliver Crook, Patrick
Kelley, Patrick Boehnke, Pau Pereira Batlle, Peter Johnson, Pieter van
den Berg , ptr, Ramiro Barrantes Reynolds, Raúl Peralta Lozada, Ravin
Kumar, Rémi , Rex Ha, Riccardo Fusaroli, Richard Nerland, Robert Frost,
Robert Goldman, Robert kohn, Robin Taylor, Ryan Grossman, Ryan Kelly, S
Hong, Sean Wilson, Sergiy Protsiv, Seth Axen, shira, Simon Duane, Simon
Lilburn, sssz, Stan\_user, Stephen Lienhard, Stew Watts, Stone Chen,
Susan Holmes, Svilup, Tao Ye, Tate Tunstall, Tatsuo Okubo, Teresa Ortiz,
Theodore Dasher, Thomas Siegert, Thomas Vladeck, Tobychev , Tomáš Frýda,
Tony Wuersch, Virginia Fisher, Vladimir Markov, Wil Yegelwel, Will Farr,
woejozney, yolhaj , yureq , Zach A, Zad Rafi, and Zhengchen Cai.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-MapRando:2024}
{``Super Metroid Map Rando.''} n.d.

\bibitem[\citeproctext]{ref-RacetimeSMR:2024}
{``Super Metroid Randomizer \textbar{} Racetime.gg.''} n.d.

\end{CSLReferences}

\section*{License}\label{license}
\addcontentsline{toc}{section}{License}

A repository containing all of the files used to generate this chapter
is available on
\href{https://github.com/betanalpha/quarto_case_studies/tree/main/case_studies/racing}{GitHub}.

The code in this case study is copyrighted by Michael Betancourt and
licensed under the new BSD (3-clause) license:

\url{https://opensource.org/licenses/BSD-3-Clause}

The text and figures in this chapter are copyrighted by Michael
Betancourt and licensed under the CC BY-NC 4.0 license:

\url{https://creativecommons.org/licenses/by-nc/4.0/}

\section*{Original Computing
Environment}\label{original-computing-environment}
\addcontentsline{toc}{section}{Original Computing Environment}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{writeLines}\NormalTok{(}\FunctionTok{readLines}\NormalTok{(}\FunctionTok{file.path}\NormalTok{(}\FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"HOME"}\NormalTok{), }\StringTok{".R/Makevars"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
CC=clang

CXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration
CXX=clang++ -arch x86_64 -ftemplate-depth-256

CXX14FLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration -Wno-unknown-pragmas
CXX14=clang++ -arch x86_64 -ftemplate-depth-256
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
R version 4.3.2 (2023-10-31)
Platform: x86_64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.4.1

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/New_York
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] colormap_0.1.4     rstan_2.32.6       StanHeaders_2.32.7

loaded via a namespace (and not attached):
 [1] gtable_0.3.4       jsonlite_1.8.8     compiler_4.3.2     Rcpp_1.0.11       
 [5] parallel_4.3.2     gridExtra_2.3      scales_1.3.0       yaml_2.3.8        
 [9] fastmap_1.1.1      ggplot2_3.4.4      R6_2.5.1           curl_5.2.0        
[13] knitr_1.45         tibble_3.2.1       munsell_0.5.0      pillar_1.9.0      
[17] rlang_1.1.2        utf8_1.2.4         V8_4.4.1           inline_0.3.19     
[21] xfun_0.41          RcppParallel_5.1.7 cli_3.6.2          magrittr_2.0.3    
[25] digest_0.6.33      grid_4.3.2         lifecycle_1.0.4    vctrs_0.6.5       
[29] evaluate_0.23      glue_1.6.2         QuickJSR_1.0.8     codetools_0.2-19  
[33] stats4_4.3.2       pkgbuild_1.4.3     fansi_1.0.6        colorspace_2.1-0  
[37] rmarkdown_2.25     matrixStats_1.2.0  tools_4.3.2        loo_2.6.0         
[41] pkgconfig_2.0.3    htmltools_0.5.7   
\end{verbatim}



\end{document}
